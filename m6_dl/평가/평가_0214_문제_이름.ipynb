{"cells":[{"cell_type":"markdown","source":["## AI기반 챗봇 및 OCR 개발 전문가 과정\n","\n","### 교과목명 : 딥러닝\n","- 평가일 : 24. 2. 14\n","- 성명 :\n","- 점수 :"],"metadata":{"id":"C0r1592zycNu"}},{"cell_type":"markdown","source":["Q1. MNIST 데이터셋에 대하여 tensorflow/keras Sequential 모델을 사용하여 아래와 같이 완전 연결 신경망(Feedforward Neural Network)을 구성한 후 모델링 및 평가를 수행하세요.\n","- 입력 형태(input_shape): input_shape=(28, 28)로 설정. 이는 모델이 28x28 픽셀 크기의 이미지를 입력으로 받는다는 것을 의미이며 첫 번째 레이어인 Flatten은 이 2D 이미지를 784(28x28) 요소의 1D 배열로 평탄화.Flatten(input_shape=(28, 28))\n","\n","- 레이어 구성: 모델은 평탄화 레이어(Flatten) 다음에 128개의 뉴런을 가진 완전 연결 레이어(Dense)를 가지고 있으며, 그 다음에는 10개의 출력 뉴런을 가진 또 다른 Dense 레이어가 있다. 출력 레이어는 소프트맥스 활성화 함수를 사용하여 다중 클래스 분류를 수행.\n","\n","- 컴파일:\n","  - optimizer='adam',\n","  - loss='sparse_categorical_crossentropy',\n","  - metrics=['accuracy']\n","\n","- epochs=5\n"],"metadata":{"id":"kUjzataoUnke"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","\n","# MNIST 데이터셋 로드\n","mnist = tf.keras.datasets.mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"QJqRFXAgU3ei"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q2. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아래사항을 준수하여  모델 학습 및 평가를 수행하세요.\n","- 데이터 정규화 (0과 1 사이의 값으로 스케일링)\n","- 입력 데이터의 차원을 (28, 28)에서 모델에 적합한 형태로 조정\n","- 레이어 연결(hidden 2개, 출력 1개)\n","- 모델 생성\n","- 모델 컴파일 : optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy']\n","- 모델 학습 : epochs=5, batch_size=32, validation_split=0.2\n","- 모델 평가"],"metadata":{"id":"vOzq316OT5GW"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","\n","# MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"o-qmSCjXJg1z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q3. 주어진 텍스트 데이터셋을 토큰화하고, 다음 사항을 수행하세요.\n","\n","데이터셋:\n","\n","\"I love machine learning.\"<br>\n","\"I love coding in Python.\"<br>\n","\"Machine learning can be fun.\"\n","\n","- 각 단어에 고유한 정수 인덱스를 할당하고 각 문장을 정수 시퀀스로 변환하세요.\n"],"metadata":{"id":"FLmwxmk27qKe"}},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","texts = ['I love machine learning', 'I love coding in Python', 'Machine learning can be fun']"],"metadata":{"id":"efGXYzt570qa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q4. Q3에서 생성한 정수 시퀀스에 패딩을 추가하여 모든 시퀀스의 길이를 동일하게 만드세요."],"metadata":{"id":"A4R79LSS6j0j"}},{"cell_type":"code","source":["from keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"iaVLgbja8Lqw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q5. 주어진 텍스트 데이터셋에 대해 원-핫 인코딩을 수행하세요. (사용할 최대 단어 수 설정 : num_words=1000)"],"metadata":{"id":"1V377ENo2iLs"}},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","\n","# 데이터셋 정의\n","texts = [ \"I love coding in Python.\",\"I love machine learning.\", \"Machine learning can be fun.\"]"],"metadata":{"id":"sQGGpgj47aEk"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
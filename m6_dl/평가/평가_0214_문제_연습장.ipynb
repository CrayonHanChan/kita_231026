{"cells":[{"cell_type":"markdown","source":["## AI기반 챗봇 및 OCR 개발 전문가 과정\n","\n","### 교과목명 : 딥러닝\n","- 평가일 : 24. 2. 14\n","- 성명 :\n","- 점수 :"],"metadata":{"id":"C0r1592zycNu"}},{"cell_type":"markdown","source":["Q1. MNIST 데이터셋에 대하여 tensorflow/keras Sequential 모델을 사용하여 아래와 같이 완전 연결 신경망(Feedforward Neural Network)을 구성한 후 모델링 및 평가를 수행하세요.\n","- 입력 형태(input_shape): input_shape=(28, 28)로 설정. 이는 모델이 28x28 픽셀 크기의 이미지를 입력으로 받는다는 것을 의미이며 첫 번째 레이어인 Flatten은 이 2D 이미지를 784(28x28) 요소의 1D 배열로 평탄화.Flatten(input_shape=(28, 28))\n","\n","- 레이어 구성: 모델은 평탄화 레이어(Flatten) 다음에 128개의 뉴런을 가진 완전 연결 레이어(Dense)를 가지고 있으며, 그 다음에는 10개의 출력 뉴런을 가진 또 다른 Dense 레이어가 있다. 출력 레이어는 소프트맥스 활성화 함수를 사용하여 다중 클래스 분류를 수행.\n","\n","- 컴파일:\n","  - optimizer='adam',\n","  - loss='sparse_categorical_crossentropy',\n","  - metrics=['accuracy']\n","\n","- epochs=5\n"],"metadata":{"id":"kUjzataoUnke"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","\n","# MNIST 데이터셋 로드\n","mnist = tf.keras.datasets.mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"QJqRFXAgU3ei","executionInfo":{"status":"ok","timestamp":1707962284587,"user_tz":-540,"elapsed":3541,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd441657-0daa-4cea-f4eb-c25d84182ff9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["model = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","model.fit(train_images, train_labels, epochs=5)\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(test_loss)\n","print(test_acc)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5U5KCGdTeWmw","executionInfo":{"status":"ok","timestamp":1707962331956,"user_tz":-540,"elapsed":44088,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"59c8d13c-3245-473b-ce8f-5cbe7ae1ef94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 9s 3ms/step - loss: 12.8356 - accuracy: 0.0970\n","Epoch 2/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 2.3118 - accuracy: 0.0987\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 2.3039 - accuracy: 0.0987\n","Epoch 4/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.0987\n","313/313 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0980\n","2.30259108543396\n","0.09799999743700027\n"]}]},{"cell_type":"code","source":["model = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","loss='sparse_categorical_crossentropy',\n","metrics=['accuracy']\n",")\n","\n","model.fit(train_images, train_labels, epochs=5)\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lF-29eFjOfX","executionInfo":{"status":"ok","timestamp":1707930058796,"user_tz":-540,"elapsed":40469,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"d6c12405-5bd8-4453-c6a6-95af46fae5cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 7s 3ms/step - loss: 2.6260 - accuracy: 0.8646\n","Epoch 2/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.4007 - accuracy: 0.9086\n","Epoch 3/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2901 - accuracy: 0.9282\n","Epoch 4/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2341 - accuracy: 0.9395\n","Epoch 5/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2222 - accuracy: 0.9448\n","313/313 [==============================] - 1s 2ms/step - loss: 0.3227 - accuracy: 0.9322\n","0.932200014591217\n"]}]},{"cell_type":"markdown","source":["Q2. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아래사항을 준수하여  모델 학습 및 평가를 수행하세요.\n","- 데이터 정규화 (0과 1 사이의 값으로 스케일링)\n","- 입력 데이터의 차원을 (28, 28)에서 모델에 적합한 형태로 조정\n","- 레이어 연결(hidden 2개, 출력 1개)\n","- 모델 생성\n","- 모델 컴파일 : optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy']\n","- 모델 학습 : epochs=5, batch_size=32, validation_split=0.2\n","- 모델 평가"],"metadata":{"id":"vOzq316OT5GW"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","\n","# MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"o-qmSCjXJg1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","\n","input_layer = Input(shape=(28, 28))\n","x = Flatten()(input_layer)\n","\n","hidden1 = Dense(128, activation='relu')(x)\n","hidden2 = Dense(64, activation='relu')(hidden1)\n","output_layer = Dense(10, activation='softmax')(hidden2)\n","\n","model = Model(inputs=input_layer, outputs=output_layer)\n","\n","model.compile(\n","    optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy']\n",")\n","model.fit(train_images, train_labels, epochs=5, batch_size=32, validation_split=0.2)\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(test_acc)\n","print(test_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83gMUaEdkU3S","executionInfo":{"status":"ok","timestamp":1707930795559,"user_tz":-540,"elapsed":42956,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"767e084a-259b-40b2-8060-39999fe5fbcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.2600 - accuracy: 0.9236 - val_loss: 0.1257 - val_accuracy: 0.9644\n","Epoch 2/5\n","1500/1500 [==============================] - 8s 5ms/step - loss: 0.1115 - accuracy: 0.9663 - val_loss: 0.1104 - val_accuracy: 0.9672\n","Epoch 3/5\n","1500/1500 [==============================] - 10s 7ms/step - loss: 0.0782 - accuracy: 0.9759 - val_loss: 0.1046 - val_accuracy: 0.9706\n","Epoch 4/5\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.0961 - val_accuracy: 0.9718\n","Epoch 5/5\n","1500/1500 [==============================] - 9s 6ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.0905 - val_accuracy: 0.9749\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9758\n","0.9757999777793884\n","0.07838941365480423\n"]}]},{"cell_type":"markdown","source":["Q3. 주어진 텍스트 데이터셋을 토큰화하고, 다음 사항을 수행하세요.\n","\n","데이터셋:\n","\n","\"I love machine learning.\"<br>\n","\"I love coding in Python.\"<br>\n","\"Machine learning can be fun.\"\n","\n","- 각 단어에 고유한 정수 인덱스를 할당하고 각 문장을 정수 시퀀스로 변환하세요.\n"],"metadata":{"id":"FLmwxmk27qKe"}},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","texts = ['I love machine learning', 'I love coding in Python', 'Machine learning can be fun']"],"metadata":{"id":"efGXYzt570qa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","print(tokenizer.word_index)\n","print(tokenizer.texts_to_sequences(texts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NW1dxYrFm0TZ","executionInfo":{"status":"ok","timestamp":1707930895362,"user_tz":-540,"elapsed":369,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"3a5269dd-6056-4c72-9b52-b31166143e70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'i': 1, 'love': 2, 'machine': 3, 'learning': 4, 'coding': 5, 'in': 6, 'python': 7, 'can': 8, 'be': 9, 'fun': 10}\n","[[1, 2, 3, 4], [1, 2, 5, 6, 7], [3, 4, 8, 9, 10]]\n"]}]},{"cell_type":"markdown","source":["Q4. Q3에서 생성한 정수 시퀀스에 패딩을 추가하여 모든 시퀀스의 길이를 동일하게 만드세요."],"metadata":{"id":"A4R79LSS6j0j"}},{"cell_type":"code","source":["from keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"iaVLgbja8Lqw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = ['I love machine learning', 'I love coding in Python', 'Machine learning can be fun']\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","seq = tokenizer.texts_to_sequences(texts)\n","print(seq)\n","seq = pad_sequences(seq, padding='post')\n","print(seq)\n","\n","word_size = len(tokenizer.word_index) + 1\n","print(to_categorical(seq, num_classes=word_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYFRjqGE8lU_","executionInfo":{"status":"ok","timestamp":1707970252392,"user_tz":-540,"elapsed":1,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"9f0258a4-0b25-4042-d5c2-a0a36bc5bf4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 2, 3, 4], [1, 2, 5, 6, 7], [3, 4, 8, 9, 10]]\n","[[ 1  2  3  4  0]\n"," [ 1  2  5  6  7]\n"," [ 3  4  8  9 10]]\n","[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n"]}]},{"cell_type":"markdown","source":["Q5. 주어진 텍스트 데이터셋에 대해 원-핫 인코딩을 수행하세요. (사용할 최대 단어 수 설정 : num_words=1000)"],"metadata":{"id":"1V377ENo2iLs"}},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","\n","# 데이터셋 정의\n","texts = [ \"I love coding in Python.\",\"I love machine learning.\", \"Machine learning can be fun.\"]"],"metadata":{"id":"sQGGpgj47aEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=1000)\n","tokenizer.fit_on_texts(texts)\n","print(tokenizer.texts_to_matrix(texts, mode='binary'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cV7aZ52-AnH","executionInfo":{"status":"ok","timestamp":1707970449650,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"a4b0964c-94a7-417a-c41f-34808735eaa2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 1. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
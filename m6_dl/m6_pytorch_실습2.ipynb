{"cells":[{"cell_type":"markdown","source":["## 모델 구조 변경\n","\n","개선된 모델(ImprovedMyModel)은 원래 모델(MyModel)에 비해 몇 가지 주요 변경사항을 포함합니다. 이러한 변경사항은 모델의 표현력을 높이고, 과적합을 방지하며, 성능을 개선하는 데 목적이 있습니다. 아래에 개선 과정을 요약해 설명합니다:\n","\n","1. 추가 컨볼루션 레이어\n","- 목적: 모델의 학습 능력을 향상시키기 위해 두 번째 컨볼루션 레이어(conv2)를 추가합니다. 이를 통해 모델은 입력 이미지에서 더 복잡하고 추상적인 특징을 추출할 수 있게 됩니다.\n","- 변경사항: ImprovedMyModel에는 (20, 40, 3) 구성을 가진 두 번째 컨볼루션 레이어가 추가됩니다. 이는 첫 번째 레이어의 출력 채널 수를 입력 채널로 받아, 출력 채널을 40으로 늘리고 커널 크기를 3으로 설정합니다.\n","2. 드롭아웃 레이어 추가\n","- 목적: 과적합을 방지하고 일반화 능력을 향상시키기 위해 드롭아웃 레이어를 추가합니다. 드롭아웃은 학습 과정에서 무작위로 일부 뉴런의 출력을 0으로 만들어, 모델이 특정 뉴런에 과도하게 의존하는 것을 방지합니다.\n","- 변경사항: dropout = nn.Dropout(0.25)를 추가하여, 각 학습 단계에서 뉴런의 25%를 무작위로 비활성화합니다.\n","3. 완전 연결 레이어의 구조 변경\n","- 목적: 추가된 컨볼루션 레이어와 드롭아웃 레이어를 통합하고, 모델의 출력 능력을 조정하기 위해 완전 연결 레이어의 구조를 변경합니다.\n","- 변경사항:\n","  - 첫 번째 완전 연결 레이어(fc1)의 입력 크기를 조정합니다. 이는 두 번째 컨볼루션 레이어와 맥스풀링 이후의 특징 맵 크기에 기반합니다.\n","  - 새로운 완전 연결 레이어(fc2)를 추가하여, 출력 크기를 60으로 설정합니다. 이를 통해 모델은 중간 표현을 더 잘 학습할 수 있습니다.\n","  - 최종 출력 레이어(fc3)는 10개의 클래스에 대한 예측을 출력합니다.\n","4. 정방향 전파 함수의 수정\n","- 목적: 모델 아키텍처의 변경사항을 반영하여 정방향 전파 과정을 수정합니다.\n","- 변경사항: 정방향 전파(forward) 함수는 두 개의 컨볼루션 레이어와 맥스풀링, 드롭아웃, 평탄화, 세 개의 완전 연결 레이어를 순차적으로 적용합니다. 이 과정은 모델이 입력 이미지에서 복잡한 특징을 추출하고, 최종적으로 분류 결정을 내리도록 합니다.\n","\n","이러한 개선을 통해 ImprovedMyModel은 더 깊은 아키텍처와 과적합 방지 기법을 사용하여 입력 데이터에서 더 정교한 특징을 학습할 수 있으며, 따라서 더 높은 성능을 달성할 가능성이 있습니다."],"metadata":{"id":"PIQt3pQhkdYD"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxd70m68sCED","executionInfo":{"status":"ok","timestamp":1708049591959,"user_tz":-540,"elapsed":18183,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"50f02215-4544-4cf9-9f26-55bead1d53ed"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Q. mnist 데이터 셋에 대해서 Pytorch를 적용하여 모델 구성 변경, 조기 학습 중단을 적용하여 학습하고 Best model을 저장한 후 다시 불러와서 테스트 데이터로 평가한 결과를 출력하세요."],"metadata":{"id":"YmMFlzh80O0B"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","import numpy as np\n","import random\n","\n","# 시드 고정 함수 정의\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # 멀티-GPU를 사용하는 경우\n","    torch.backends.cudnn.deterministic = True # 모델의 학습과 추론 과정이 완전히 재현 가능하도록 보장\n","    torch.backends.cudnn.benchmark = False # 동적 벤치마킹 과정을 비활성화하고, 더 일관된 연산 성능을 제공\n","    torch.use_deterministic_algorithms(True) # 애플리케이션 전반에 걸쳐 결정론적 알고리즘 사용을 강제\n","\n","# 시드 고정 함수 호출\n","set_seed(42)\n","\n","# MNIST 데이터셋을 위한 전처리 과정 정의\n","# 모델의 학습 효율성을 향상시키고, 일반적으로 신경망에서 더 나은 성능을 얻기 위해 널리 사용\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 높이, 너비, 채널(예: RGB)의 3차원 배열을 0과 1 사이의 값으로 스케일링된 텐서로 변경\n","    transforms.Normalize((0.5,), (0.5,))  # 이미지를 평균 0.5, 표준편차 0.5로 정규화하여 [-1, 1] 범위로 조정\n","])\n","\n","# MNIST 데이터셋 로드\n","# transform=transform: 이미지에 적용할 전처리 과정을 지정\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# 훈련 데이터셋을 훈련 및 검증 세트로 분할\n","train_size = int(0.8 * len(train_dataset))  # 훈련 세트 크기를 전체의 80%로 설정\n","val_size = len(train_dataset) - train_size  # 검증 세트 크기 계산\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])  # 분할 실행\n","\n","# DataLoader는 데이터셋에서 미니 배치를 자동으로 생성하고, 이를 모델 학습이나 평가에 이용할 수 있게 해주는 유틸리티\n","trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True) # 데이터를 로드하기 전에 데이터셋을 무작위로 섞기\n","valloader = DataLoader(val_dataset, batch_size=64, shuffle=False) # 데이터의 순서가 성능 평가에 영향을 미치지 않는다.\n","testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# 모델 아키텍처 정의\n","# ImprovedMyModel 클래스는 1채널 그레이스케일 이미지를 입력으로 받아, 10개의 출력 클래스를 가지는 분류 문제에 사용될 수 있는 구조\n","class ImprovedMyModel(nn.Module):\n","    def __init__(self):\n","        super(ImprovedMyModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5)  # 첫 번째 컨볼루션 레이어 # 커널사이즈는 5by5\n","        self.pool = nn.MaxPool2d(2, 2)  # 맥스풀링 레이어 # 4개중에 가장큰거 고르고 나머지 삭제하는 맥스풀링..\n","        self.conv2 = nn.Conv2d(20, 40, 3)  # 두 번째 컨볼루션 레이어 추가 (출력 채널 40, 커널 크기 3)\n","        self.dropout = nn.Dropout(0.25)  # 드롭아웃 추가 (드롭아웃 확률 0.25)\n","        self.flatten = nn.Flatten()  # 텐서 평탄화\n","        # 첫 번째 완전 연결 레이어의 입력 크기를 조정해야 할 수 있음\n","        self.fc1 = nn.Linear(40 * 5 * 5, 120)  # 입력 크기 조정, 출력 크기를 120으로 변경\n","        # 40*5*5는 픽셀사이즈가 위에서 평탄화하면서 이렇게 되는데 그과정에서 40*5*5 으로 되는것..\n","        self.fc2 = nn.Linear(120, 60)  # 새로운 완전 연결 레이어 추가 (출력 크기 60)\n","        self.fc3 = nn.Linear(60, 10)  # 최종 출력 레이어 (클래스 수 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))  # 첫 번째 컨볼루션 + 맥스풀링 # 비선형활성화 하고 그것을 풀링까지..\n","        x = self.pool(F.relu(self.conv2(x)))  # 두 번째 컨볼루션 + 맥스풀링\n","        x = self.dropout(x)  # 드롭아웃 적용\n","        x = self.flatten(x)  # 평탄화\n","        x = F.relu(self.fc1(x))  # 첫 번째 완전 연결 레이어 + ReLU\n","        x = F.relu(self.fc2(x))  # 두 번째 완전 연결 레이어 + ReLU\n","        x = self.fc3(x)  # 최종 출력\n","        return x\n","\n","model = ImprovedMyModel()  # 모델 인스턴스 생성\n","\n","# 손실 함수 및 최적화 알고리즘 지정\n","criterion = nn.CrossEntropyLoss()  # 크로스 엔트로피 손실 함수\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # SGD 최적화 알고리즘\n","\n","# 모델 훈련\n","best_val_loss = float('inf')  # 검증 손실 값을 무한대로 초기화. 처음에는 모든 검증 손실이 이 값보다 작다고 가정\n","patience, trials = 5, 0  # 조기 종료 기준 설정\n","num_epochs = 20  # 에폭 수 설정\n","for epoch in range(num_epochs):\n","    model.train()  # 모델을 훈련 모드로 설정\n","    running_loss = 0.0\n","    for inputs, labels in trainloader:\n","        optimizer.zero_grad()  # 그래디언트 초기화\n","        outputs = model(inputs)  # 모델을 통한 순전파\n","        loss = criterion(outputs, labels)  # 손실 계산\n","        loss.backward()  # 역전파\n","        optimizer.step()  # 파라미터 업데이트\n","        running_loss += loss.item()\n","\n","    # 검증 단계\n","    val_loss = 0.0\n","    model.eval()  # 모델을 평가 모드로 설정\n","    with torch.no_grad():\n","        for inputs, labels in valloader:\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    val_loss /= len(valloader)  # 평균 검증 손실 계산\n","    print(f'Epoch {epoch+1}, Train Loss: {running_loss / len(trainloader)}, Val Loss: {val_loss}')\n","\n","    # 검증 손실이 개선되었는지 확인하고 모델 저장\n","    if val_loss < best_val_loss:\n","        print(f'Validation Loss Decreased({best_val_loss:.6f}--->{val_loss:.6f}) \\t Saving The Model')\n","        best_val_loss = val_loss\n","        trials = 0\n","        save_path = \"/content/drive/MyDrive/hjh_kita_directory/Github/kita_231026/m6_dl/data/model/best_model2.pth\"\n","        torch.save(model.state_dict(), save_path)  # 모델 저장\n","    else:\n","        trials += 1\n","        if trials >= patience:  # 조기 종료 조건 충족 확인\n","            print(\"Early stopping triggered\")\n","            break\n","\n","# 최고의 모델을 불러와서 평가\n","model.load_state_dict(torch.load(save_path))  # 모델 상태 불러오기\n","\n","# 모델 평가\n","correct = 0\n","total = 0\n","with torch.no_grad():  # 그래디언트 계산 비활성화\n","    for inputs, labels in testloader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1) # max_values, max_indices = torch.max(t, dim=1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total  # 정확도 계산\n","print(f'Accuracy on the 10000 test images: {accuracy}%')  # 정확도 출력"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zGy0vU2eSFE","executionInfo":{"status":"ok","timestamp":1708050666578,"user_tz":-540,"elapsed":594549,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"b0ac2b8f-23ef-4bca-c7db-f9bc027069e0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 94230262.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 24506513.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 24908577.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 37427364.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Epoch 1, Train Loss: 0.4320345055907965, Val Loss: 0.0927548280476216\n","Validation Loss Decreased(inf--->0.092755) \t Saving The Model\n","Epoch 2, Train Loss: 0.07796046690115084, Val Loss: 0.056028031976893544\n","Validation Loss Decreased(0.092755--->0.056028) \t Saving The Model\n","Epoch 3, Train Loss: 0.058214919812666875, Val Loss: 0.049590681532169986\n","Validation Loss Decreased(0.056028--->0.049591) \t Saving The Model\n","Epoch 4, Train Loss: 0.04520329272622863, Val Loss: 0.046049785912978126\n","Validation Loss Decreased(0.049591--->0.046050) \t Saving The Model\n","Epoch 5, Train Loss: 0.037527246068464595, Val Loss: 0.038781398403559854\n","Validation Loss Decreased(0.046050--->0.038781) \t Saving The Model\n","Epoch 6, Train Loss: 0.03308063800306991, Val Loss: 0.039987441042575615\n","Epoch 7, Train Loss: 0.029733163448555085, Val Loss: 0.03948143626095113\n","Epoch 8, Train Loss: 0.02570551196912614, Val Loss: 0.037455865078571036\n","Validation Loss Decreased(0.038781--->0.037456) \t Saving The Model\n","Epoch 9, Train Loss: 0.022646312187057142, Val Loss: 0.03811862255075694\n","Epoch 10, Train Loss: 0.019761739309566716, Val Loss: 0.04063264821176764\n","Epoch 11, Train Loss: 0.01926478083988574, Val Loss: 0.033823613462950465\n","Validation Loss Decreased(0.037456--->0.033824) \t Saving The Model\n","Epoch 12, Train Loss: 0.01912245569502314, Val Loss: 0.034294647853691476\n","Epoch 13, Train Loss: 0.016043742910706593, Val Loss: 0.041813915914470735\n","Epoch 14, Train Loss: 0.015964191459226035, Val Loss: 0.03890404324734613\n","Epoch 15, Train Loss: 0.013846328747754644, Val Loss: 0.03782368653295673\n","Epoch 16, Train Loss: 0.01312408153899984, Val Loss: 0.03265500947921456\n","Validation Loss Decreased(0.033824--->0.032655) \t Saving The Model\n","Epoch 17, Train Loss: 0.013374501480066102, Val Loss: 0.032337274556955384\n","Validation Loss Decreased(0.032655--->0.032337) \t Saving The Model\n","Epoch 18, Train Loss: 0.010308117302059449, Val Loss: 0.03425439825759121\n","Epoch 19, Train Loss: 0.010810057665551237, Val Loss: 0.033058829812566824\n","Epoch 20, Train Loss: 0.010486358210878583, Val Loss: 0.03482075160346985\n","Accuracy on the 10000 test images: 99.24%\n"]}]},{"cell_type":"markdown","source":["Q. 저장된 모델 best_model2.pth를 불러와서 epochs 10을 추가하여 학습한 후 test 데이터로 평가를 수행하고 모델을 best_model3.pth로 저장하세요."],"metadata":{"id":"gDnFjpDNAKIm"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","import numpy as np\n","import random\n","\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends_cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_seed(42)\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_size = int"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"vuyEBbv8zlJC","executionInfo":{"status":"error","timestamp":1708051776901,"user_tz":-540,"elapsed":5,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"e69b8107-c46d-4efe-da0f-9492f8aa4a4a"},"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"expected ':' (<ipython-input-4-b2cc6186ae63>, line 12)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-b2cc6186ae63>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    def set_seed(seed=42)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"]}]},{"cell_type":"code","source":["eimport torch\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","import numpy as np\n","import random\n","\n","# 시드 고정 함수 정의\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # 멀티-GPU를 사용하는 경우\n","    torch.backends.cudnn.deterministic = True # 모델의 학습과 추론 과정이 완전히 재현 가능하도록 보장\n","    torch.backends.cudnn.benchmark = False # 동적 벤치마킹 과정을 비활성화하고, 더 일관된 연산 성능을 제공\n","\n","# 시드 고정 함수 호출\n","set_seed(42)\n","\n","# MNIST 데이터셋을 위한 전처리 과정 정의\n","# 모델의 학습 효율성을 향상시키고, 일반적으로 신경망에서 더 나은 성능을 얻기 위해 널리 사용\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 높이, 너비, 채널(예: RGB)의 3차원 배열을 0과 1 사이의 값으로 스케일링된 텐서로 변경\n","    transforms.Normalize((0.5,), (0.5,))  # 이미지를 평균 0.5, 표준편차 0.5로 정규화하여 [-1, 1] 범위로 조정\n","])\n","\n","# MNIST 데이터셋 로드\n","# transform=transform: 이미지에 적용할 전처리 과정을 지정\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# 훈련 데이터셋을 훈련 및 검증 세트로 분할\n","train_size = int(0.8 * len(train_dataset))  # 훈련 세트 크기를 전체의 80%로 설정\n","val_size = len(train_dataset) - train_size  # 검증 세트 크기 계산\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])  # 분할 실행\n","\n","# DataLoader는 데이터셋에서 미니 배치를 자동으로 생성하고, 이를 모델 학습이나 평가에 이용할 수 있게 해주는 유틸리티\n","trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True) # 데이터를 로드하기 전에 데이터셋을 무작위로 섞기\n","valloader = DataLoader(val_dataset, batch_size=64, shuffle=False) # 데이터의 순서가 성능 평가에 영향을 미치지 않는다.\n","testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# 모델 아키텍처 정의\n","# ImprovedMyModel 클래스는 1채널 그레이스케일 이미지를 입력으로 받아, 10개의 출력 클래스를 가지는 분류 문제에 사용될 수 있는 구조\n","class ImprovedMyModel(nn.Module):\n","    def __init__(self):\n","        super(ImprovedMyModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5)  # 첫 번째 컨볼루션 레이어\n","        self.pool = nn.MaxPool2d(2, 2)  # 맥스풀링 레이어\n","        self.conv2 = nn.Conv2d(20, 40, 3)  # 두 번째 컨볼루션 레이어 추가 (출력 채널 40, 커널 크기 3)\n","        self.dropout = nn.Dropout(0.25)  # 드롭아웃 추가 (드롭아웃 확률 0.25)\n","        self.flatten = nn.Flatten()  # 텐서 평탄화\n","        # 첫 번째 완전 연결 레이어의 입력 크기를 조정해야 할 수 있음\n","        self.fc1 = nn.Linear(40 * 5 * 5, 120)  # 입력 크기 조정, 출력 크기를 120으로 변경\n","        self.fc2 = nn.Linear(120, 60)  # 새로운 완전 연결 레이어 추가 (출력 크기 60)\n","        self.fc3 = nn.Linear(60, 10)  # 최종 출력 레이어 (클래스 수 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))  # 첫 번째 컨볼루션 + 맥스풀링\n","        x = self.pool(F.relu(self.conv2(x)))  # 두 번째 컨볼루션 + 맥스풀링\n","        x = self.dropout(x)  # 드롭아웃 적용\n","        x = self.flatten(x)  # 평탄화\n","        x = F.relu(self.fc1(x))  # 첫 번째 완전 연결 레이어 + ReLU\n","        x = F.relu(self.fc2(x))  # 두 번째 완전 연결 레이어 + ReLU\n","        x = self.fc3(x)  # 최종 출력\n","        return x\n","\n","# 모델 아키텍처 인스턴스 생성\n","model = ImprovedMyModel()\n","\n","# 저장된 state_dict 불러오기\n","state_dict = torch.load('/content/drive/MyDrive/hjh_kita_directory/Github/kita_231026/m6_dl/data/model/best_model2.pth')\n","\n","# 불러온 state_dict를 모델에 로드\n","model.load_state_dict(state_dict)\n","\n","# 모델 구조 출력\n","print(model)\n","\n","# 손실 함수 및 최적화 알고리즘 지정\n","criterion = nn.CrossEntropyLoss()  # 크로스 엔트로피 손실 함수\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # SGD 최적화 알고리즘\n","\n","# epochs 추가 학습을 위한 설정\n","num_additional_epochs = 10\n","for epoch in range(num_additional_epochs):\n","    model.train()  # 모델을 훈련 모드로 설정\n","    running_loss = 0.0\n","    for inputs, labels in trainloader:\n","        optimizer.zero_grad()  # 그래디언트 초기화\n","        outputs = model(inputs)  # 모델을 통한 순전파\n","        loss = criterion(outputs, labels)  # 손실 계산\n","        loss.backward()  # 역전파\n","        optimizer.step()  # 파라미터 업데이트\n","        running_loss += loss.item()\n","    # 여기서는 간단화를 위해 검증 단계는 생략했습니다. 필요에 따라 추가하세요.\n","    print(f'Epoch {epoch+1}, Train Loss: {running_loss / len(trainloader)}')\n","\n","\n","# 모델 평가\n","correct = 0\n","total = 0\n","with torch.no_grad():  # 그래디언트 계산 비활성화\n","    for inputs, labels in testloader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total  # 정확도 계산\n","print(f'Accuracy on the 10000 test images: {accuracy}%')  # 정확도 출력\n","\n","import os\n","# Define the save path\n","save_path = '/content/drive/MyDrive/hjh_kita_directory/Github/kita_231026/m6_dl/data/model/best_model3.pth'\n","\n","# Ensure directory exists\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","\n","# 모델의 매개변수(가중치와 편향)만 저장\n","torch.save(model.state_dict(), save_path)\n","print(\"Saved PyTorch Model State to model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jrCK0ag9sZ4","executionInfo":{"status":"ok","timestamp":1708051341520,"user_tz":-540,"elapsed":268854,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"91cf4bfd-3081-4289-95dd-27b0e52476e2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ImprovedMyModel(\n","  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n","  (dropout): Dropout(p=0.25, inplace=False)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=1000, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",")\n","Epoch 1, Train Loss: 0.010379539783309156\n","Epoch 2, Train Loss: 0.011699398231581047\n","Epoch 3, Train Loss: 0.00912322826905923\n","Epoch 4, Train Loss: 0.009984595322600702\n","Epoch 5, Train Loss: 0.009502588192047067\n","Epoch 6, Train Loss: 0.008114215796119727\n","Epoch 7, Train Loss: 0.008531275776411348\n","Epoch 8, Train Loss: 0.00936103180717934\n","Epoch 9, Train Loss: 0.00803397601218118\n","Epoch 10, Train Loss: 0.008708202411192663\n","Accuracy on the 10000 test images: 99.09%\n","Saved PyTorch Model State to model.pth\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
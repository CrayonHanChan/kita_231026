{"cells":[{"cell_type":"markdown","source":["## PyTorch 소개\n","- 딥러닝 연구와 개발을 위한 오픈 소스 머신러닝 라이브러리로, 다양한 딥러닝 모델을 구축하고 학습시키기 위한 강력한 도구와 API를 제공합니다.\n","- PyTorch는 'define-by-run' 접근 방식을 사용하여, 모델을 실행하는 동안 계산 그래프를 동적으로 구성합니다. 이는 개발 과정에서 더 많은 유연성을 제공하며, 디버깅과 모델 수정을 쉽게 만들어 줍니다.\n","- Pythonic한 디자인을 갖추고 있어, Python 및 NumPy와 긴밀하게 통합되어 있습니다. 이로 인해 사용자는 Python의 기본 기능을 최대한 활용할 수 있으며, PyTorch 코드를 쉽게 작성하고 이해할 수 있습니다.\n","- 모듈을 통해, 모델의 파라미터에 대한 그래디언트(가중치의 기울기)를 자동으로 계산할 수 있습니다. 이 기능은 모델 학습 시 역전파(오차 업데이트)를 간단하게 구현할 수 있게 해 줍니다.\n","- 전반적으로 유연한 설계를 가지고 있으며, 사용자가 모델의 세부 사항을 더 세밀하게 제어할 수 있게 합니다.\n","\n"],"metadata":{"id":"o_YUpO9mY7kz"}},{"cell_type":"markdown","source":["## 파이토치의 구성요소\n","\n","- `torch`: 메인 네임스페이스, 텐서 등의 다양한 수학 함수가 포함\n","- `torch.autograd`: 자동 미분 기능을 제공하는 라이브러리\n","- `torch.nn`: 신경망 구축을 위한 데이터 구조나 레이어 등의 라이브러리\n","- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n","- `torch.optim`: SGD(Stochastic Gradient Descent)를 중심으로 한 파라미터 최적화 알고리즘 제공\n","- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n","- `torch.onnx`: ONNX(Open Neural Network Exchange), 서로 다른 프레임워크 간의 모델을 공유할 때 사용"],"metadata":{"id":"s8UPdbcC96kb"}},{"cell_type":"markdown","source":["## 텐서(Tensors)\n","\n","* 데이터 표현을 위한 기본 구조로 텐서(tensor)를 사용\n","* 텐서는 데이터를 담기위한 컨테이너(container)로서 일반적으로 수치형 데이터를 저장\n","* 넘파이(NumPy)의 ndarray와 유사\n","* GPU를 사용한 연산 가속 가능(원래 numpy scikitlearn 는 GPU가 안됨)\n","\n","[ ndarray와 텐서 비교 ]\n","- GPU 지원: PyTorch의 Tensor와 TensorFlow의 텐서는 GPU를 통한 가속을 지원. 이는 대규모 배열 연산에서 상당한 성능 향상을 가져올 수 있는 반면, NumPy ndarray는 기본적으로 CPU에서만 작동.\n","- 자동 미분 지원: PyTorch와 TensorFlow는 딥러닝 모델 학습을 위해 자동 미분을 지원하는 반면, NumPy는 이러한 기능을 내장하고 있지 않다. 이는 신경망의 역전파와 같은 복잡한 연산을 구현할 때 중요한 차이점이다.(가중치들을 손실함수를 최소화되도록 업데이트 해야하는데.. 즉 기울기 순간변화율 - 비용함수최소화하는 것들로 모델을 결정을 하면 됨 근데 그때 가중치가 많은데, 그때 편미분을 함. )\n","- API 호환성: PyTorch와 TensorFlow/Keras는 NumPy와의 호환성을 중시하며, 많은 경우에 NumPy의 API를 모방. 이는 NumPy 사용자가 쉽게 이러한 프레임워크로 전환할 수 있도록 돕는다. 그러나 각 프레임워크는 자체적인 최적화와 기능을 제공하기 때문에, 모든 NumPy 연산이 그대로 사용될 수 있는 것은 아니다.\n","\n","[ PyTorch와 TensorFlow/Keras에서의 ndarray 사용 ]\n","- PyTorch에서의 사용: PyTorch는 torch.from_numpy() 함수를 통해 NumPy ndarray를 PyTorch의 Tensor로 변환할 수 있다. 변환된 텐서는 원래 ndarray와 메모리를 공유하기 때문에, 한 객체의 변경이 다른 객체에도 반영된다. 반대로, .numpy() 메소드를 사용하여 PyTorch 텐서를 NumPy 배열로 변환할 수 있다.\n","- TensorFlow/Keras에서의 사용: TensorFlow에서는 tf.convert_to_tensor() 함수를 사용하여 NumPy ndarray를 TensorFlow의 텐서로 변환할 수 있다. 이 변환된 텐서는 TensorFlow 연산에 사용될 수 있다. TensorFlow 텐서를 NumPy 배열로 변환하기 위해서는 .numpy() 메소드를 사용할 수 있다.\n","\n","PyTorch와 TensorFlow/Keras 모두 NumPy ndarray와의 상호 운용성을 지원하며, 이를 통해 각 프레임워크의 텐서로 쉽게 변환할 수 있다. 각 프레임워크의 텐서는 GPU 지원과 자동 미분과 같은 추가적인 기능을 제공하여 딥러닝 모델의 개발과 학습을 효율적으로 할 수 있게 한다."],"metadata":{"id":"AZs8Ioo3-T9k"}},{"cell_type":"markdown","source":["3D Tensor\n","\n","* 큐브(cube)와 같은 모양으로 세개의 축이 존재\n","* 데이터가 연속된 시퀀스 데이터나 시간 축이 포함된 시계열 데이터에 해당\n","* 주식 가격 데이터셋, 시간에 따른 질병 발병 데이터 등이 존재\n","* 주로 샘플(samples), 타임스텝(timesteps), 특성(features)을 가진 구조로 사용\n","\n","4D Tensor\n","\n","* 4개의 축\n","* 컬러 이미지 데이터가 대표적인 사례 (흑백 이미지 데이터는 3D Tensor로 가능)\n","* 주로 샘플(samples), 높이(height), 너비(width), 컬러 채널(channel)을 가진 구조로 사용 - 흑백 이미지는 컬러 채널을 생략하기도 함. 이때는 4D가 아닌 3D가 됨\n","\n","5D Tensor\n","\n","* 5개의 축\n","* 비디오 데이터가 대표적인 사례\n","* 주로 샘플(samples), 프레임(frames), 높이(height), 너비(width), 컬러 채널(channel)을 가진 구조로 사용"],"metadata":{"id":"o-LcoaFq-xgC"}},{"cell_type":"markdown","source":["PyTorch 텐서의 주요 dtype:\n","\n","부동 소수점 타입:\n","- torch.float64 또는 torch.double: 64-bit 부동 소수점\n","- torch.float32 또는 torch.float: 32-bit 부동 소수점 (기본값)\n","- torch.float16 또는 torch.half: 16-bit 부동 소수점. 메모리를 절약하고 계산 속도를 높이고자 할 때 유용\n","- torch.bfloat16: 16-bit 부동 소수점, reduced precision than torch.float16. 넓은 수치 범위를 다뤄야 하며 하드웨어 지원이 있는 환경에서 대규모 딥러닝 모델 학습에 더 적합\n","\n","정수 타입:\n","- torch.int64 또는 torch.long: 64-bit 정수\n","- torch.int32 또는 torch.int: 32-bit 정수\n","- torch.int16 또는 torch.short: 16-bit 정수\n","- torch.int8: 8-bit 정수\n","- torch.uint8: 8-bit 부호 없는(unsigned) 정수. 0부터 255까지의 정수 값을 표현할 수 있으며, 주로 이미지 데이터를 다룰 때 사용"],"metadata":{"id":"Z9jCOFcX3TEY"}},{"cell_type":"code","source":["# 비트가 높으면 정밀한 반면에 메모리가 많이 소요된다.\n","# 예를 들어, 그래픽 처리나 머신러닝에서 대량의 데이터 처리시에는 float32,\n","# 과학적 계산이나 금융 모델링 같이 정밀도가 필요한 경우 float64 사용.(torch.float16 에서는 15-17진수 까지 가능)\n","import torch\n","\n","# Float32 tensor\n","tensor_float32 = torch.randn(3, 4) # 정규분포를 이루는 3행 4열 짜리를 만듦\n","# default 가 32비트로 되어있음.\n","\n","tensor_float32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6_vYLNB5m33","executionInfo":{"status":"ok","timestamp":1707784828211,"user_tz":-540,"elapsed":480,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"fd4e8756-474d-42df-ae7e-a5cec8075cbf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.8011,  0.1219, -1.0125,  0.1818],\n","        [-0.0174, -1.1910,  0.4616, -1.3121],\n","        [ 0.4252,  0.4685, -0.0652,  1.2411]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["tensor_float64 = tensor_float32.to(dtype=torch.float64)\n","tensor_float64\n","# 타입 바꿔도 결과는 같고 타입만 바뀜. 이때는 32 로 쓰는게 좋음(메모리 절약)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnctci3h6HCV","executionInfo":{"status":"ok","timestamp":1707784862883,"user_tz":-540,"elapsed":388,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"e273edf8-3639-43fc-b92a-1680f7ca610d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.8011,  0.1219, -1.0125,  0.1818],\n","        [-0.0174, -1.1910,  0.4616, -1.3121],\n","        [ 0.4252,  0.4685, -0.0652,  1.2411]], dtype=torch.float64)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 텐서에 대한 수학 연산, 삼각함수, 비트 연산, 비교 연산, 집계 등 제공\n","import math\n","\n","a = torch.randn(1,2) * 2 - 1 # 표준 정규 분포(평균 = 0, 표준 편차 = 1)에서 가져온 값의 각 요소에 2를 곱한 다음 1을 뺀다.\n","print(a)\n","print(\"절대값(abs):\", torch.abs(a)) # 절대값\n","print(\"천장(ceil):\", torch.ceil(a)) # 텐서 a의 각 요소에 천장 함수를 적용. ex) -2.1731 의 천장은 -2. 2.1731의 천장은 3\n","print(\"바닥(floor):\", torch.floor(a)) # 텐서 a의 각 요소에 바닥 함수를 적용 ex) -2.1731 의 바닥은 -3. 2.1731의 바닥은 2\n","print(\"clamp함수:\", torch.clamp(a,-0.5,0.5))\n","# '-0.5' 이하의 값은 '-0.5'로 설정되고, '0.5' 이상의 값은 '0.5'로 설정. ex) -2.1731은 -0.5, 2.1731은 0.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80UJjxNX9nUy","executionInfo":{"status":"ok","timestamp":1707786202721,"user_tz":-540,"elapsed":398,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"2ed0aacb-5bd3-41f1-9c0e-e426b5957472"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-2.3617, -0.4285]])\n","절대값(abs): tensor([[2.3617, 0.4285]])\n","천장(ceil): tensor([[-2., -0.]])\n","바닥(floor): tensor([[-3., -1.]])\n","clamp함수: tensor([[-0.5000, -0.4285]])\n"]}]},{"cell_type":"markdown","source":["`in-place` 방식\n","  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n","  - `x.copy_(y), x.t_()`"],"metadata":{"id":"XCLg8saWAgJq"}},{"cell_type":"code","source":["x = torch.rand(2,2) # 무작위로 생성된 행렬을 반환\n","print(x)\n","y = torch.rand(2,2)\n","print(y)\n","print(x)\n","print(y)\n","print()\n","y.add_(x) #  _가 있는 add_는 메서드가 y 자체를 변경한다는 의미이며 y의 값이 변경\n","print(y) # 원본 y 가 바뀜(add_ 함수로 x를 더함.)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1r8KHo-TAhOq","executionInfo":{"status":"ok","timestamp":1707786322031,"user_tz":-540,"elapsed":402,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"52b9c3ca-1928-448c-a4e5-b68f04f159a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4803, 0.7577],\n","        [0.6774, 0.0802]])\n","tensor([[0.5193, 0.4231],\n","        [0.8718, 0.9108]])\n","tensor([[0.4803, 0.7577],\n","        [0.6774, 0.0802]])\n","tensor([[0.5193, 0.4231],\n","        [0.8718, 0.9108]])\n","\n","tensor([[0.9997, 1.1808],\n","        [1.5492, 0.9910]])\n"]}]},{"cell_type":"markdown","source":["`torch.mm`: 내적(dot product)"],"metadata":{"id":"ocg6U3BZAyqp"}},{"cell_type":"code","source":["x = torch.rand(2,2)\n","print(x)\n","print(y, '\\n')\n","print(torch.matmul(x,y), '\\n')\n","z = torch.mm(x,y) # torch.matmul = torch.mm\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlEd7U6GAceB","executionInfo":{"status":"ok","timestamp":1707786570189,"user_tz":-540,"elapsed":557,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"dff68766-cd32-416b-d1b1-8adf795c49c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.3327, 0.7171],\n","        [0.6102, 0.4801]])\n","tensor([[1.1295, 1.2627],\n","        [1.2542, 0.4179]]) \n","\n","tensor([[1.2753, 0.7198],\n","        [1.2914, 0.9711]]) \n","\n","tensor([[1.2753, 0.7198],\n","        [1.2914, 0.9711]])\n"]}]},{"cell_type":"markdown","source":["인덱싱(Indexing): NumPy처럼 인덱싱 형태로 사용가능"],"metadata":{"id":"AwI_cl0MBH8n"}},{"cell_type":"code","source":["import torch\n","x = torch.Tensor([[1, 2], [3, 4]]) # torch.Tensor() 로 만들기.\n","print(x)\n","\n","# numpy 처럼 인덱싱으로 사용할수 있음\n","print(x[0, 0])\n","print(x[0, 1])\n","print(x[1, 0])\n","print(x[1, 1])\n","print(x[:, 0])\n","print(x[:, 1])\n","print(x[0, :])\n","print(x[1, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIT9OdrIBPT-","executionInfo":{"status":"ok","timestamp":1707786804395,"user_tz":-540,"elapsed":396,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"53ada95f-27ae-40df-f5ce-1406389e3698"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2.],\n","        [3., 4.]])\n","tensor(1.)\n","tensor(2.)\n","tensor(3.)\n","tensor(4.)\n","tensor([1., 3.])\n","tensor([2., 4.])\n","tensor([1., 2.])\n","tensor([3., 4.])\n"]}]},{"cell_type":"markdown","source":["Q. 주어진 텐서 t에 대하여 다음을 수행하세요.\n","- 텐서 t의 두 번째 행을 선택하세요.\n","- 텐서 t의 첫 번째 열을 선택하세요.\n","- 텐서 t의 마지막 열을 선택하세요.\n","- 텐서 t의 대각선에 있는 요소들을 선택하세요.\n","- 텐서 t의 첫 두 행과 첫 두 열에 있는 요소들을 선택하여 부분 행렬을 만드세요."],"metadata":{"id":"z50qRs0qJ6lf"}},{"cell_type":"code","source":["# 주어진 텐서 t\n","import torch\n","\n","# Create a sample tensor for indexing exercises\n","t = torch.tensor([\n","    [1, 2, 3],\n","    [4, 5, 6],\n","    [7, 8, 9]\n","])"],"metadata":{"id":"ydj4gbfxJ3kp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A.\n","print(\"두 번째 행:\", t[1,:])\n","print(\"첫 번째 행:\", t[:,1])\n","print(\"마지막 열:\", t[:,-1])\n","print(\"대각선:\", torch.diag(t))\n","print(\"부분 행렬:\", t[0:2, 0:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dM86NTfPB2z1","executionInfo":{"status":"ok","timestamp":1707787402498,"user_tz":-540,"elapsed":391,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"c2fe0a66-813a-4301-822c-45d7e03f12c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["두 번째 행: tensor([4, 5, 6])\n","첫 번째 행: tensor([2, 5, 8])\n","마지막 열: tensor([3, 6, 9])\n","대각선: tensor([1, 5, 9])\n","부분 행렬: tensor([[1, 2],\n","        [4, 5]])\n"]}]},{"cell_type":"markdown","source":["º 랜덤한 값을 가지는 텐서 생성\n","\n","1. torch.rand() : 0과 1 사이의 숫자를 균등하게 생성\n","\n","2. torch.rand_like() : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n","\n","3. torch.randn() : 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용해 생성\n","\n","4. torch.randn_like() :  사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n","\n","5. torch.randint() : 주어진 범위 내의 정수를 균등하게 생성\n","\n","6. torch.randint_like() : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n","\n","7. torch.randperm() : 주어진 범위 내의 정수를 랜덤하게 생성\n"],"metadata":{"id":"oUoiDWZxBYi0"}},{"cell_type":"code","source":["import torch\n","\n","# Create a tensor with random values\n","tensor_rand = torch.rand(3, 3)\n","existing_tensor = torch.tensor([[1,2], [3,4]])\n","tensor_rand_like = torch.rand_like(existing_tensor, dtype=torch.float)\n","tensor_randn = torch.randn(3,3)\n","tensor_randn_like = torch.randn_like(existing_tensor, dtype=torch.float)\n","tensor_randint = torch.randint(0, 10, (3,3)) # 10은 제외\n","tensor_randint_like = torch.randint_like(existing_tensor, low=0, high=10, dtype=torch.int)\n","tensor_randperm = torch.randperm(10) # 10은 제외\n","\n","tensor_rand, existing_tensor, tensor_rand_like, tensor_randn, tensor_randn_like, tensor_randint, tensor_randint_like, tensor_randperm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zDSJ7d2Eqtj","executionInfo":{"status":"ok","timestamp":1707788030081,"user_tz":-540,"elapsed":400,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"2d2b9aca-0d05-437f-e9b7-fe23d7994d73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.3640, 0.1827, 0.0272],\n","         [0.1297, 0.8369, 0.3662],\n","         [0.4514, 0.0925, 0.0220]]),\n"," tensor([[1, 2],\n","         [3, 4]]),\n"," tensor([[0.4732, 0.3169],\n","         [0.0396, 0.1843]]),\n"," tensor([[-1.4027, -1.7395, -0.1041],\n","         [-1.2078,  1.3834,  1.4691],\n","         [ 0.0499,  1.0223, -0.2353]]),\n"," tensor([[-0.0750,  0.4926],\n","         [-1.3268, -0.1557]]),\n"," tensor([[1, 5, 4],\n","         [2, 1, 0],\n","         [6, 8, 5]]),\n"," tensor([[4, 4],\n","         [3, 5]], dtype=torch.int32),\n"," tensor([9, 1, 4, 7, 2, 0, 6, 3, 8, 5]))"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Q. 파이토치 랜덤 값으로 다음 사항을 수행하세요.\n","- 연습 1: 0과 1 사이의 균등 분포에서 난수를 생성하여 3행 5열 텐서를 만드세요.\n","- 연습 2: 평균이 0이고 표준편차가 1인 정규 분포에서 난수를 생성하여 2행 3열 텐서를 만드세요.\n","- 연습 3: 0부터 9까지의 범위에서 균등 분포 정수 난수를 생성하여 3행 3열 텐서를 만드세요.\n","- 연습 4: 0부터 9까지의 숫자를 무작위로 섞어서 텐서를 만드세요.\n","- 연습 5: -10부터 10까지 5개의 균등한 간격으로 나뉜 실수 값을 가진 텐서를 만드세요."],"metadata":{"id":"VcJ-G4wJLG55"}},{"cell_type":"code","source":["# 연습 1: 0과 1 사이의 균등 분포에서 난수를 생성하여 3행 5열 텐서를 만드세요.\n","practice1 = torch.rand(3, 5)\n","practice1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SO-iUKZ1GZdY","executionInfo":{"status":"ok","timestamp":1707788136721,"user_tz":-540,"elapsed":1,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"5943e949-2f6d-4065-fb95-f6e998d6ab24"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8247, 0.0612, 0.4525, 0.7226, 0.9844],\n","        [0.6782, 0.5540, 0.2289, 0.9683, 0.5535],\n","        [0.7457, 0.0484, 0.0518, 0.3970, 0.6528]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# 연습 2: 평균이 0이고 표준편차가 1인 정규 분포에서 난수를 생성하여 2행 3열 텐서를 만드세요.\n","practice2 = torch.randn(2, 3)\n","practice2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yEHF0wVhGvlo","executionInfo":{"status":"ok","timestamp":1707788207185,"user_tz":-540,"elapsed":569,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"40bf0b3d-eedf-4f32-fdcb-d6e23e21b16f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.4215, -1.3039, -0.6938],\n","        [ 0.0562, -1.3942,  1.7088]])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# 연습 3: 0부터 9까지의 범위에서 균등 분포 정수 난수를 생성하여 3행 3열 텐서를 만드세요.\n","practice3 = torch.randint(0, 10, (3,3))\n","practice3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BH4MIqvgHPXA","executionInfo":{"status":"ok","timestamp":1707788338885,"user_tz":-540,"elapsed":499,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"cb9c73b0-6864-4342-f49d-d1b4ae557cd2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[6, 4, 9],\n","        [5, 2, 1],\n","        [7, 0, 9]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# 연습 4: 0부터 9까지의 숫자를 무작위로 섞어서 텐서를 만드세요.\n","practice4 = torch.randperm(10)\n","practice4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCgTJftbHfyO","executionInfo":{"status":"ok","timestamp":1707788432329,"user_tz":-540,"elapsed":394,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"c6c69cae-bc28-4a1b-e091-e83e45224768"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 0, 9, 2, 7, 4, 6, 8, 5, 3])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# 연습 5: -10부터 10까지 5개의 균등한 간격으로 나뉜 실수 값을 가진 텐서를 만드세요.\n","practice5 = torch.linspace(-10, 10, steps=5)\n","practice5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSA0ucJqH3n8","executionInfo":{"status":"ok","timestamp":1707788647784,"user_tz":-540,"elapsed":426,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"76cf94a4-3d05-4fcb-bb32-a3dc69244620"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-10.,  -5.,   0.,   5.,  10.])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["º 특정한 값을 가지는 텐서 생성\n","\n","1. torch.arange() : 주어진 범위 내의 정수를 순서대로 생성\n","\n","2. torch.ones() : 주어진 사이즈의 1로 이루어진 텐서 생성\n","\n","3. torch.zeros() : 주어진 사이즈의 0으로 이루어진 텐서 생성\n","\n","4. torch.ones_like() : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n","\n","5. torch.zeros_like() : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n","\n","6. torch.linspace() : 시작점과 끝점을 주어진 갯수만큼 균등하게 나눈 간격점을 행벡터로 출력\n","\n","7. torch.logspace() : 시작점과 끝점을 주어진 갯수만큼 로그간격으로 나눈 간격점을 행벡터로 출력"],"metadata":{"id":"VDTzGMqoK0pN"}},{"cell_type":"code","source":["# Create a tensor with a specific value\n","tensor_arange = torch.arange(0,10)\n","tensor_ones = torch.ones(3,3)\n","tensor_zeros = torch.zeros(3,3)\n","tensor_ones_like = torch.ones_like(existing_tensor)\n","tensor_zeros_like = torch.zeros_like(existing_tensor)\n","tensor_linspace = torch.linspace(0, 10, steps=5)\n","tensor_logspace = torch.logspace(start=-1, end=1, steps=5) # start가 -1 인데 0.1로 시작해서 10까지에서 5개 스텝으로..\n","# 로그. 밑을 10으로 함. start=-1 -> 10의 -1승은 0.1, end=1 -> 10의 1승은 10\n","\n","# Output for demonstration\n","tensor_arange, tensor_ones, tensor_ones_like, tensor_zeros_like, tensor_linspace, tensor_logspace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h05v5Ni0JCrK","executionInfo":{"status":"ok","timestamp":1707788958256,"user_tz":-540,"elapsed":471,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"bfdb7081-f7cf-49f4-c31e-efff7a90259d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n"," tensor([[1., 1., 1.],\n","         [1., 1., 1.],\n","         [1., 1., 1.]]),\n"," tensor([[1, 1],\n","         [1, 1]]),\n"," tensor([[0, 0],\n","         [0, 0]]),\n"," tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000]),\n"," tensor([ 0.1000,  0.3162,  1.0000,  3.1623, 10.0000]))"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# Create a tensor with a specific value\n","tensor_arange = torch.arange(0, 10)  # 1\n","tensor_ones = torch.ones(3, 3)  # 2\n","tensor_zeros = torch.zeros(3, 3)  # 3\n","tensor_ones_like = torch.ones_like(existing_tensor)  # 4\n","tensor_zeros_like = torch.zeros_like(existing_tensor)  # 5\n","tensor_linspace = torch.linspace(0, 10, steps=5)  # 6\n","tensor_logspace = torch.logspace(start=-1, end=1, steps=5)  # 7\n","\n","# Output for demonstration\n","tensor_arange, tensor_ones, tensor_zeros, tensor_ones_like, tensor_zeros_like, tensor_linspace, tensor_logspace\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GprK8ZICPyY","executionInfo":{"status":"ok","timestamp":1707788745000,"user_tz":-540,"elapsed":416,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"3d6e932a-a3ef-4e7c-f6c5-d4a46c64130d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n"," tensor([[1., 1., 1.],\n","         [1., 1., 1.],\n","         [1., 1., 1.]]),\n"," tensor([[0., 0., 0.],\n","         [0., 0., 0.],\n","         [0., 0., 0.]]),\n"," tensor([[1, 1],\n","         [1, 1]]),\n"," tensor([[0, 0],\n","         [0, 0]]),\n"," tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000]),\n"," tensor([ 0.1000,  0.3162,  1.0000,  3.1623, 10.0000]))"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["#### Python 에서 size와 shape는 텐서의 차원을 나타내는 데 사용되며 사실상 같은 기능을 제공. 차이는 size가 메소드인데 반하여 shape는 속성."],"metadata":{"id":"Qwhjuy3tNwLM"}},{"cell_type":"markdown","source":["`view`: 텐서의 크기(size)나 모양(shape)을 변경\n","\n","- 기본적으로 변경 전과 후에 텐서 안의 원소 개수가 유지되어야 함\n","- -1로 설정되면 계산을 통해 해당 크기값을 유추"],"metadata":{"id":"6J77KlnKBr0I"}},{"cell_type":"code","source":["# view() 함수는 텐서의 크기를 변경\n","# reshape 기능의 view()\n","x = torch.randn(4,5)\n","print(x, '\\n')\n","\n","y = x.view(20)\n","print(y, '\\n')\n","z = x.view(5,-1)\n","print(z)\n","\n","print(x.view(-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5G1w_pWcNb2W","executionInfo":{"status":"ok","timestamp":1707790217375,"user_tz":-540,"elapsed":518,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"196aa09e-ee91-41df-d569-4f07a0ea0dfe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.7931,  0.0760, -0.3839,  1.1723, -0.6292],\n","        [ 0.3104,  0.7929, -0.5998,  0.3525,  0.1950],\n","        [ 0.7707,  0.3076,  0.9732, -0.1813, -1.4114],\n","        [ 1.0128,  0.6976,  0.7464, -2.4147, -1.1220]]) \n","\n","tensor([ 0.7931,  0.0760, -0.3839,  1.1723, -0.6292,  0.3104,  0.7929, -0.5998,\n","         0.3525,  0.1950,  0.7707,  0.3076,  0.9732, -0.1813, -1.4114,  1.0128,\n","         0.6976,  0.7464, -2.4147, -1.1220]) \n","\n","tensor([[ 0.7931,  0.0760, -0.3839,  1.1723],\n","        [-0.6292,  0.3104,  0.7929, -0.5998],\n","        [ 0.3525,  0.1950,  0.7707,  0.3076],\n","        [ 0.9732, -0.1813, -1.4114,  1.0128],\n","        [ 0.6976,  0.7464, -2.4147, -1.1220]])\n","tensor([ 0.7931,  0.0760, -0.3839,  1.1723, -0.6292,  0.3104,  0.7929, -0.5998,\n","         0.3525,  0.1950,  0.7707,  0.3076,  0.9732, -0.1813, -1.4114,  1.0128,\n","         0.6976,  0.7464, -2.4147, -1.1220])\n"]}]},{"cell_type":"code","source":["# 'item': 텐서에서 값에서 숫자값을 얻을 수 있음. 1by1행렬에서만 사용할 수 있음.\n","x = torch.randn(1)\n","# x = torch.randn(2) # 1개가 아니라 2로 하게 되면 오류가 나는데, 1개 일때만 사용가능함\n","print(x)\n","print(x.item()) # item() 함수는 텐서의 값을 Python의 숫자로 반환하며 텐서에서 값만 추출\n","print(x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHuEDFa4O1tA","executionInfo":{"status":"ok","timestamp":1707790410313,"user_tz":-540,"elapsed":396,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"d2a4498d-a4a1-4faa-f059-60cc3faf93dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.7034])\n","-0.703370213508606\n","torch.float32\n"]}]},{"cell_type":"markdown","source":["squeeze() 함수는 크기가 1인 입력 텐서의 모든 차원을 제거하는 데 사용\n","- dim이 제공되지 않으면 squeeze()는 텐서에서 크기 1의 모든 차원을 제거\n","- dim이 제공되면 크기가 1인 경우에만 지정된 차원만 제거. 즉 (1, 2, 1, 3)인 텐서가 있고 dim이 2이면 결과의 크기는 (1, 2, 3)"],"metadata":{"id":"3wuuGDBKQaDU"}},{"cell_type":"code","source":["# `squeeze`: 차원을 축소(제거)\n","tensor = torch.rand(1,3,3)\n","print(tensor)\n","print(tensor.shape)\n","\n","t = tensor.squeeze()\n","print(t)\n","print(t.shape)\n","# 3차원인데 층이 1개 였어서(크기가 1인 경우 지정된 차원을 제거) 층이 사라지고 2차원만 남음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPH5QVzDDO6S","executionInfo":{"status":"ok","timestamp":1707736937331,"user_tz":-540,"elapsed":793,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"e0ab6c7c-2406-421a-bb98-614d040199ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.7190, 0.3570, 0.8358],\n","         [0.6716, 0.3720, 0.9981],\n","         [0.8401, 0.1728, 0.8925]]])\n","torch.Size([1, 3, 3])\n","tensor([[0.7190, 0.3570, 0.8358],\n","        [0.6716, 0.3720, 0.9981],\n","        [0.8401, 0.1728, 0.8925]])\n","torch.Size([3, 3])\n"]}]},{"cell_type":"markdown","source":["tensor.unsqueeze(dim=2)\n","\n","- unsqueeze 함수는 텐서에 새로운 차원을 추가. 여기서 dim=2는 새로운 차원이 추가될 위치를 나타내며 기존 텐서의 모든 차원의 인덱스를 증가시키고, 새로운 차원은 dim=2에 위치.\n","\n","- 원래 텐서의 모양(shape)이 (3, 4)이었다면, unsqueeze(dim=2)를 적용한 후의 모양은 (3, 4, 1)이 됩니다. 따라서, 이 코드에서는 기존 텐서에 1차원을 추가"],"metadata":{"id":"hdxpdHPbD2Iq"}},{"cell_type":"code","source":["t = torch.rand(3,3)\n","print(t)\n","print(t.shape)\n","\n","tensor = t.unsqueeze(dim=0)\n","print(tensor)\n","print(tensor.shape)\n","# 2차원이었는데 3차원으로 차원업해줌"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2AL40s9DdFa","executionInfo":{"status":"ok","timestamp":1707791110261,"user_tz":-540,"elapsed":425,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"621149e0-de0d-4054-88de-83798af3bb0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6954, 0.9890, 0.6538],\n","        [0.0688, 0.8689, 0.6390],\n","        [0.5310, 0.4162, 0.0866]])\n","torch.Size([3, 3])\n","tensor([[[0.6954, 0.9890, 0.6538],\n","         [0.0688, 0.8689, 0.6390],\n","         [0.5310, 0.4162, 0.0866]]])\n","torch.Size([1, 3, 3])\n"]}]},{"cell_type":"code","source":["tensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tiFSNZEqEFAi","executionInfo":{"status":"ok","timestamp":1707791112002,"user_tz":-540,"elapsed":397,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"8cc22e02-57ce-4609-d20f-246a009d77b1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 3])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["tensor = tensor.unsqueeze(dim=2)\n","print(tensor)\n","print(tensor.shape)\n","# [1,3,3] 이었는데 dim=2자리(인덱스2) 에 차원 하나를 추가 그래서 [1,3,1(추가),3] 이렇게 됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUutoKF5D3Li","executionInfo":{"status":"ok","timestamp":1707791113746,"user_tz":-540,"elapsed":427,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"1ef42ed8-4b6a-42ea-9678-5459a481d989"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[0.6954, 0.9890, 0.6538]],\n","\n","         [[0.0688, 0.8689, 0.6390]],\n","\n","         [[0.5310, 0.4162, 0.0866]]]])\n","torch.Size([1, 3, 1, 3])\n"]}]},{"cell_type":"markdown","source":["Q. 아래 텐서를 torch.Size([3, 5])로 변경하세요."],"metadata":{"id":"dwXdqQSVOasy"}},{"cell_type":"code","source":["# 주어진 텐서\n","import torch\n","\n","# 초기 텐서 생성\n","tensor_for_squeeze = torch.randn(1, 3, 1, 5)\n","print(\"차원 축소 전 텐서 (squeeze 전):\\n\", tensor_for_squeeze)\n","print(\"차원 축소 전 형태:\", tensor_for_squeeze.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7gDkDjwOT4w","executionInfo":{"status":"ok","timestamp":1707791169939,"user_tz":-540,"elapsed":407,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"bbb0355d-27e1-41ba-a601-d0d063ba93cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["차원 축소 전 텐서 (squeeze 전):\n"," tensor([[[[-1.0263,  1.6038,  1.1499, -1.0408, -0.8213]],\n","\n","         [[ 0.1637, -0.4179,  0.2153, -0.6421, -1.6621]],\n","\n","         [[-1.8789,  0.3394,  0.0436, -0.9087, -1.4259]]]])\n","차원 축소 전 형태: torch.Size([1, 3, 1, 5])\n"]}]},{"cell_type":"code","source":["# A.\n","t = tensor_for_squeeze.squeeze() # dim 을 안주고 squeeze()함수 쓰면 크기가 1인 차원을 모두 제거\n","t, t.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrGINFrTSVcn","executionInfo":{"status":"ok","timestamp":1707791335284,"user_tz":-540,"elapsed":516,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"ae3d98cc-385c-4926-a3b0-0cff013a33c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-1.0263,  1.6038,  1.1499, -1.0408, -0.8213],\n","         [ 0.1637, -0.4179,  0.2153, -0.6421, -1.6621],\n","         [-1.8789,  0.3394,  0.0436, -0.9087, -1.4259]]),\n"," torch.Size([3, 5]))"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["Q. 아래 텐서를 torch.Size([1, 3, 5])로 변경하세요."],"metadata":{"id":"ElZKJKjvPUIT"}},{"cell_type":"code","source":["# 초기 텐서 생성\n","tensor_for_unsqueeze = torch.randn(3, 5)\n","print(\"\\n차원 확장 전 텐서 (unsqueeze 전):\\n\", tensor_for_unsqueeze)\n","print(\"차원 확장 전 형태:\", tensor_for_unsqueeze.shape)"],"metadata":{"id":"oLzhdVBhOyIy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707791409006,"user_tz":-540,"elapsed":413,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"0574cc1b-1646-4305-9071-7cc1febc6861"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","차원 확장 전 텐서 (unsqueeze 전):\n"," tensor([[-0.0961, -1.9999,  0.0560, -0.8750,  0.2082],\n","        [-1.0046,  0.9410, -1.5435,  0.4429,  0.5584],\n","        [-0.6139, -0.7685, -1.0731, -0.6651, -0.6774]])\n","차원 확장 전 형태: torch.Size([3, 5])\n"]}]},{"cell_type":"code","source":["# A.\n","t = tensor_for_unsqueeze.unsqueeze(dim=0)\n","# t = tensor_for_unsqueeze.unsqueeze() # 이 상황에선 dim을 생략해줘도됨\n","t, t.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bnvhy8jHTIT4","executionInfo":{"status":"ok","timestamp":1707791429014,"user_tz":-540,"elapsed":632,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"fd53d703-88fe-45b3-8928-2ea85c47b3b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[-0.0961, -1.9999,  0.0560, -0.8750,  0.2082],\n","          [-1.0046,  0.9410, -1.5435,  0.4429,  0.5584],\n","          [-0.6139, -0.7685, -1.0731, -0.6651, -0.6774]]]),\n"," torch.Size([1, 3, 5]))"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["Q. 2행 3열 텐서의 크기를 3행 2열로 변경하세요.\n","- view 사용\n","- reshape 사용\n","- transpose 사용"],"metadata":{"id":"8HnQaPI-NQZd"}},{"cell_type":"code","source":["# 주어진 텐서\n","import torch\n","\n","# 초기 텐서 생성\n","initial_tensor = torch.randn(2, 3)\n","print(\"초기 텐서:\\n\", initial_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yea3WDeVNHCO","executionInfo":{"status":"ok","timestamp":1707791986713,"user_tz":-540,"elapsed":483,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"4fb9d009-853d-43f1-8558-8523c33248cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["초기 텐서:\n"," tensor([[-1.2727,  0.8804,  3.4701],\n","        [ 0.6773,  0.3058, -0.2899]])\n"]}]},{"cell_type":"code","source":["# A.\n","# view 사용\n","view = initial_tensor.view(3, 2)\n","print(view, view.shape)\n","\n","# reshape 사용\n","reshape =initial_tensor.reshape(3, 2)\n","print(reshape, reshape.shape)\n","\n","# transpose 사용\n","transpose = torch.transpose(initial_tensor, 0, 1)\n","print(transpose, transpose.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U58OC_7GTXqw","executionInfo":{"status":"ok","timestamp":1707792369283,"user_tz":-540,"elapsed":419,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"320372d5-2435-463d-fc86-e24e571a5275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.2727,  0.8804],\n","        [ 3.4701,  0.6773],\n","        [ 0.3058, -0.2899]]) torch.Size([3, 2])\n","tensor([[-1.2727,  0.8804],\n","        [ 3.4701,  0.6773],\n","        [ 0.3058, -0.2899]]) torch.Size([3, 2])\n","tensor([[-1.2727,  0.6773],\n","        [ 0.8804,  0.3058],\n","        [ 3.4701, -0.2899]]) torch.Size([3, 2])\n"]}]},{"cell_type":"markdown","source":["view 와 reshape 가 표면적으로 같아 보이지만 차이가 있음.\n"],"metadata":{"id":"OJo9RZtAXB4k"}},{"cell_type":"code","source":["x = torch.arange(8).view(2, 4)\n","y_view = x.view(4,2)\n","y_view"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tUF06sOBXQjM","executionInfo":{"status":"ok","timestamp":1707792493800,"user_tz":-540,"elapsed":403,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"a698d592-a063-4715-fc0c-1a97d4339c1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1],\n","        [2, 3],\n","        [4, 5],\n","        [6, 7]])"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["# view 와 reshape의 차이점을 알아보기\n","x_transposed = x.t() # 전치.\n","y_view = x_transposed.view(2,4)\n","y_view\n","# 실행해 보면 RuntimeError 가 남."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"id":"hsYdM-BhXdC0","executionInfo":{"status":"error","timestamp":1707792582112,"user_tz":-540,"elapsed":394,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"5ff8ed1e-aa8c-4091-b8e0-fd78f9dcf2b7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-5ef844b48f48>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# view 와 reshape의 차이점을 알아보기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_transposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 전치.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_transposed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError 가 남.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."]}]},{"cell_type":"code","source":["# view는 메모리가 연속적인 경우에서 유효한 반면 reshape는 메모리가 연속적이지 않아도 작동하여 유연하게 사용 가능\n","x_transposed = x.t() # 전치.\n","y_reshape = x_transposed.reshape(2,4)\n","y_reshape\n","# reshape 로 하면 잘 나옴"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-aMU4GuXr-u","executionInfo":{"status":"ok","timestamp":1707792635971,"user_tz":-540,"elapsed":386,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"663e0598-6085-46b2-d2ca-bec857b96cd3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 4, 1, 5],\n","        [2, 6, 3, 7]])"]},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","source":["stack은 새로운 차원을 추가하여 텐서들을 결합하는 반면, cat은 기존 차원을 따라 텐서들을 연결\n","\n","- stack : 새로운 차원이 추가되며, 해당 차원의 크기는 결합할 텐서들의 개수\n","- cat: 주어진 텐서들을 기존 차원을 따라 연결하여 결합"],"metadata":{"id":"H46g6UMXEPsS"}},{"cell_type":"code","source":["import torch\n","x = torch.FloatTensor([1,4])\n","print(x)\n","y = torch.FloatTensor([2,5])\n","print(y)\n","z = torch.FloatTensor([3,6])\n","print(z)\n","print(torch.stack([x,y,z]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjc4dVIAEPCH","executionInfo":{"status":"ok","timestamp":1707876858256,"user_tz":-540,"elapsed":348,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"e5e08fef-b482-4c76-86ae-60f26ae83c60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 4.])\n","tensor([2., 5.])\n","tensor([3., 6.])\n","tensor([[1., 4.],\n","        [2., 5.],\n","        [3., 6.]])\n"]}]},{"cell_type":"code","source":["a = torch.randn(1,3,3)\n","print(a,'\\n')\n","b = torch.randn(1,3,3)\n","print(b,'\\n')\n","c = torch.cat((a,b), dim=0)\n","print(c,'\\n')\n","print(c.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnakasQ9EXk2","executionInfo":{"status":"ok","timestamp":1707876673769,"user_tz":-540,"elapsed":360,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"6db6fb69-e4e7-445b-f52b-2cae96b0140f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.5966,  0.6897, -0.8582],\n","         [ 0.1386, -0.3039, -0.6772],\n","         [-1.6966,  0.4806, -0.3541]]]) \n","\n","tensor([[[-0.1025, -0.0920,  1.7002],\n","         [-0.8404, -0.0184,  1.3941],\n","         [-1.4658,  0.8520,  0.3321]]]) \n","\n","tensor([[[ 0.5966,  0.6897, -0.8582],\n","         [ 0.1386, -0.3039, -0.6772],\n","         [-1.6966,  0.4806, -0.3541]],\n","\n","        [[-0.1025, -0.0920,  1.7002],\n","         [-0.8404, -0.0184,  1.3941],\n","         [-1.4658,  0.8520,  0.3321]]]) \n","\n","torch.Size([2, 3, 3])\n"]}]},{"cell_type":"code","source":["a = torch.randn(3,3)\n","print(a, '\\n')\n","b = torch.randn(3,3)\n","print(b, '\\n')\n","# c = torch.randn(3,3)\n","# print(c, '\\n')g\n","s = torch.stack([a,b], dim=0)\n","s, s.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_B_vSlIOXC-1","executionInfo":{"status":"ok","timestamp":1707876692151,"user_tz":-540,"elapsed":332,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"ace6394d-ef67-4d36-a122-9261bd3b104f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.8964, -0.9523,  1.2786],\n","        [ 0.3266, -0.7755, -2.1145],\n","        [ 1.0999, -0.5245, -0.0537]]) \n","\n","tensor([[ 1.8042,  0.0123, -1.6636],\n","        [-0.9665,  0.9136,  0.8838],\n","        [-0.4163,  1.4937, -1.9646]]) \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0.8964, -0.9523,  1.2786],\n","          [ 0.3266, -0.7755, -2.1145],\n","          [ 1.0999, -0.5245, -0.0537]],\n"," \n","         [[ 1.8042,  0.0123, -1.6636],\n","          [-0.9665,  0.9136,  0.8838],\n","          [-0.4163,  1.4937, -1.9646]]]),\n"," torch.Size([2, 3, 3]))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["chunk: 텐서를 여러 개로 나눌 때 사용 (몇 개로 나눌 것인가?)\n","\n","split: chunk와 동일한 기능이지만 조금 다름 (텐서의 크기는 몇인가?)\n","- 열방향으로 최대 2개를 가짐"],"metadata":{"id":"5-CusK8HFjYa"}},{"cell_type":"code","source":["# chunk -> 몇 개로 나눌 것인가?\n","# 6열을 3개로 나누면.. 2열씩 3개로 나눠짐\n","tensor = torch.rand(3,6)\n","print(tensor)\n","\n","t1,t2, t3 = torch.chunk(tensor, 3, dim=1)\n","print(t1, t1.shape)\n","print(t2)\n","print(t3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4s7KLOY7F_LY","executionInfo":{"status":"ok","timestamp":1707877361862,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"81afaabc-825b-4c3a-95c5-578bd17146a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2734, 0.5700, 0.2754, 0.5948, 0.3042, 0.4159],\n","        [0.8023, 0.5994, 0.9548, 0.8075, 0.5071, 0.6776],\n","        [0.2195, 0.9649, 0.7862, 0.9763, 0.2549, 0.0154]])\n","tensor([[0.2734, 0.5700],\n","        [0.8023, 0.5994],\n","        [0.2195, 0.9649]]) torch.Size([3, 2])\n","tensor([[0.2754, 0.5948],\n","        [0.9548, 0.8075],\n","        [0.7862, 0.9763]])\n","tensor([[0.3042, 0.4159],\n","        [0.5071, 0.6776],\n","        [0.2549, 0.0154]])\n"]}]},{"cell_type":"code","source":["# split -> 텐서의 크기는 몇인가?\n","# 6열에서 텐서의 크기 3으로 하면.. 3열씩 2개로 나눠짐\n","tensor = torch.rand(3,6)\n","t1, t2, t3 = torch.split(tensor, 2, dim=1)\n","# t1, t2 = torch.split(tensor, 3, dim =1)\n","print(tensor)\n","print(t1, t1.shape)\n","print(t2)\n","print(t3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b8PcxumFzp_","executionInfo":{"status":"ok","timestamp":1707877425795,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"2dd13228-69cd-4c2a-823e-b79b8e2fd710"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1636, 0.8746, 0.0160, 0.2424, 0.8775, 0.3051],\n","        [0.1947, 0.2316, 0.3737, 0.6352, 0.4861, 0.0348],\n","        [0.8657, 0.7716, 0.1271, 0.8081, 0.4324, 0.8585]])\n","tensor([[0.1636, 0.8746],\n","        [0.1947, 0.2316],\n","        [0.8657, 0.7716]]) torch.Size([3, 2])\n","tensor([[0.0160, 0.2424],\n","        [0.3737, 0.6352],\n","        [0.1271, 0.8081]])\n","tensor([[0.8775, 0.3051],\n","        [0.4861, 0.0348],\n","        [0.4324, 0.8585]])\n"]}]},{"cell_type":"markdown","source":["torch ↔ numpy\n","- Torch Tensor(텐서)를 NumPy array(배열)로 변환 가능\n","  - `numpy()`\n","  - `from_numpy()`\n","- Tensor가 CPU상에 있다면 NumPy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"],"metadata":{"id":"vBe1MqlBGauy"}},{"cell_type":"markdown","source":["[ CPU 메모리 (일반적으로 RAM이라고 함) ]\n","- 접근성: CPU 메모리는 컴퓨터의 주 메모리로 사용되며, CPU가 직접 접근할 수 있는 메모리입니다. 시스템의 대부분의 연산과 데이터 처리는 CPU 메모리를 통해 이루어집니다.\n","- 용량: 일반적으로 GPU 메모리보다 큰 용량을 가지고 있으며, 대규모 데이터셋을 저장하거나 복잡한 애플리케이션을 실행하는 데 적합합니다.\n","- 유연성: CPU 메모리는 다양한 타입의 데이터와 프로그램을 유연하게 처리할 수 있습니다.\n","\n","[ GPU 메모리 ]\n","- 고속 연산: GPU 메모리는 GPU에 의해 직접 접근되며, 대규모 병렬 연산에 최적화되어 있습니다. GPU 메모리는 고속으로 데이터를 읽고 쓸 수 있어, 복잡한 수학적 연산과 그래픽 처리에 이점을 제공합니다.\n","- 용량 제한: GPU 메모리는 일반적으로 CPU 메모리보다 용량이 작습니다. 이는 특히 대규모 모델을 학습시키거나 높은 해상도의 그래픽 작업을 수행할 때 제약 사항이 될 수 있습니다.\n","- 특수 목적: GPU 메모리는 주로 그래픽 처리와 병렬 수치 연산에 사용됩니다. 딥러닝과 같은 과제에서 GPU를 사용하면 상당한 성능 향상을 얻을 수 있습니다.\n","\n","[ 데이터 이동 ]\n","\n","- CPU와 GPU 간의 데이터 이동은 명시적으로 수행되어야 합니다. 예를 들어, PyTorch에서는 .to() 메소드 또는 .cuda()/.cpu() 메소드를 사용하여 텐서를 명시적으로 GPU나 CPU 메모리로 이동시킵니다. 이 과정은 추가적인 시간이 소요될 수 있으며, 특히 대량의 데이터를 이동시킬 때는 성능에 영향을 줄 수 있습니다.\n","\n","[ CPU 메모리로 이동시키는 것의 의미 ]\n","- 호환성과 접근성: CPU 메모리로 데이터를 이동시키는 것은 계산 호환성과 접근성을 확보하는 데 중요합니다. GPU는 계산 속도를 크게 향상시킬 수 있지만, 모든 시스템이나 환경에서 GPU를 사용할 수 있는 것은 아닙니다. CPU에서 작업할 수 있도록 데이터를 이동시키면, GPU가 없는 환경에서도 코드 실행이 가능합니다.\n","- 메모리 관리: GPU 메모리는 한정되어 있고, 대규모 데이터셋 또는 큰 모델을 처리할 때 메모리 부족 문제에 직면할 수 있습니다. CPU 메모리로 데이터를 이동시키면, 이러한 메모리 부족 문제를 회피할 수 있습니다. 또한, 데이터를 분석하거나 시각화하는 등의 작업을 위해 때때로 데이터를 CPU로 이동시킬 필요가 있습니다.\n","- 데이터 저장 및 전송: 학습이 완료된 모델의 가중치나 예측 결과와 같은 데이터를 저장하거나 다른 시스템으로 전송하기 위해서는 대개 CPU 메모리 상에 위치해야 합니다. 이런 경우, 데이터를 CPU로 이동시켜 파일 시스템에 쉽게 저장하거나 네트워크를 통해 전송할 수 있습니다."],"metadata":{"id":"dqGUeMgGyFl-"}},{"cell_type":"code","source":["# 이용가능한 장치에 따라서 설정해주면 됨. cpu쓰면 cpu로, gpu쓰면 gpu쓰면 됨\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73zj3kA8Gev1","executionInfo":{"status":"ok","timestamp":1707878286900,"user_tz":-540,"elapsed":431,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"ccc76e24-21db-4f48-a6b9-579bed54284a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["a = torch.ones(7)\n","print(a)\n","print(a.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRY7AMc8Gmyr","executionInfo":{"status":"ok","timestamp":1707878287898,"user_tz":-540,"elapsed":1,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"f5516926-621c-4bf2-c978-7b79be9e7c21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1.])\n","torch.float32\n"]}]},{"cell_type":"code","source":["# .to('cpu')는 텐서를 CPU 메모리로 이동시킵니다.\n","# gpu쓰는데 굳이 이렇게 cpu로 쓰는 일은 거의 없는데 알아만 두기\n","# torch.double는 텐서의 데이터 타입을 64-bit floating point로 변환. torch.double은 torch.float64와 동일\n","print(a.to('cpu', torch.double))\n","print(type(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLMFtgRMcm2Q","executionInfo":{"status":"ok","timestamp":1707878289220,"user_tz":-540,"elapsed":474,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"a33d8e91-5912-497a-b45f-692335859949"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["# 텐서 'a'가 아직 CPU에 없으면 CPU로 이동. 텐서 a의 데이터 유형을 PyTorch의 데이터 유형인 torch.double로 변환\n","print(a.to('cpu', torch.double))\n","print(type(a))\n","\n","# a 는 텐서"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQpi1dEpGuip","executionInfo":{"status":"ok","timestamp":1707878290139,"user_tz":-540,"elapsed":427,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"c6c8aad5-45f6-48ee-cf7a-965ecb49fd13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["b = a.numpy()\n","print(b)\n","print(type(b))\n","\n","# b는 배열"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruEvdXvfG32v","executionInfo":{"status":"ok","timestamp":1707878291001,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"761b83c3-4df8-4363-d75a-f1b056d89be5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 1. 1. 1. 1. 1. 1.]\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["c = torch.from_numpy(b)\n","print(c)\n","print(type(c))\n","\n","# c는 텐서"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gj0CfevDdeDe","executionInfo":{"status":"ok","timestamp":1707878292419,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"d361c461-5f9e-434c-9467-d18e9588f231"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1.])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["a.add_(1) # a값에 1을 더해 줌\n","# add_ 는 inplace효과. _ 언더바는 원본에 반영하게됨.\n","print(a)\n","print(type(a))\n","print(b)\n","print(type(b))\n","print(c)\n","print(type(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2dpcJZ3HJ_G","executionInfo":{"status":"ok","timestamp":1707878293640,"user_tz":-540,"elapsed":1,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"afff49a1-9bba-48e9-e7c4-0912570e79cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 2., 2., 2., 2., 2., 2.])\n","<class 'torch.Tensor'>\n","[2. 2. 2. 2. 2. 2. 2.]\n","<class 'numpy.ndarray'>\n","tensor([2., 2., 2., 2., 2., 2., 2.])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["# 모델을 cpu로 작업하기 원하는 경우(그럴일은 거의 없을 것임.)\n","model = model.to('cpu') # 첫번째 방법\n","model = model.cpu() # 두번째 방법"],"metadata":{"id":"Uk6QvDezhk2u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q. NumPy 배열 [1, 2, 3, 4, 5]를 생성하고 이를 PyTorch 텐서로 변환하세요."],"metadata":{"id":"Pd2l_EBIeKW0"}},{"cell_type":"code","source":["# A.\n","import numpy as np\n","numpy_array = np.array([1,2,3,4,5])\n","\n","torch_tensor = torch.from_numpy(numpy_array)\n","\n","print(torch_tensor)\n","print(type(torch_tensor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pGV_Gd1erxb","executionInfo":{"status":"ok","timestamp":1707878770896,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"edcb0a0c-3695-4e3f-c5c3-900a6bb136f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 4, 5])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"markdown","source":["Q. PyTorch 텐서 torch.tensor([10, 20, 30, 40, 50])를 생성하고 이를 NumPy 배열로 변환하세요."],"metadata":{"id":"RiO76iAheLrj"}},{"cell_type":"code","source":["torch_tensor = torch.tensor([10, 20, 30, 40, 50])\n","numpy_array = torch_tensor.numpy()\n","print(numpy_array)\n","print(type(numpy_array))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYBFEMiLfBaT","executionInfo":{"status":"ok","timestamp":1707878714024,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"72715c23-83d5-4dce-dc02-6c37b33a320c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[10 20 30 40 50]\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","source":["## 모델 구성\n","PyTorch 모델은 모델 아키텍처 정의, 손실 함수 지정, 최적화 프로그램 선택 등 여러 주요 단계가 필요하며 일반적으로 torch.nn.Module(nn = neural network)을 서브클래싱하고 __init__ 및 forward 메서드를 구현하여 정의됩니다.\n","\n","[ 데이터 준비 ]\n","\n","데이터셋을 위한 전처리 과정 정의, 로드, 훈련 데이터셋을 훈련 및 검증 세트로 분할\n","\n","[ 모델 아키텍처 정의 ]\n","\n","PyTorch로 모델을 만들 때는 모델이 어떻게 생겼는지 설계하고, 모델이 학습하는 동안 어떻게 성능을 측정할지 결정하며, 모델을 개선하기 위해 어떤 방법을 사용할지 선택하는 것을 포함합니다. PyTorch의 torch.nn.Module 클래스를 기반으로 새로운 클래스를 만들어 이 모든 것을 구현합니다.\n","- __init__에서 레이어 초기화<br>\n","__init__ 메소드 내에서 모델의 레이어와 매개변수를 정의합니다. PyTorch는 완전히 연결된 레이어를 위한 'nn.Linear', 컨볼루션 레이어를 위한 'nn.Conv2d' 등과 같은 'torch.nn' 모듈에 내장된 레이어의 포괄적인 컬렉션을 제공합니다.\n","- forward 메소드 구현<br>\n","forward 방법은 모델이 입력 데이터를 처리하는 방법을 정의합니다. 여기서는 모델의 순방향 전달을 지정하고 필요에 따라 레이어를 연결하고 활성화 기능을 적용합니다.\n","\n","[ 손실 함수 지정 ]\n","- 모델을 정의한 후에는 모델의 예측이 목표 데이터와 얼마나 잘 일치하는지 측정하는 손실 함수를 지정해야 합니다. PyTorch는 'torch.nn'에서 분류 작업을 위한 'nn.CrossEntropyLoss', 회귀 작업을 위한 'nn.MSELoss'와 같은 몇 가지 일반적인 손실 함수를 제공합니다.\n","\n","[ 최적화 프로그램을 선택 ]\n","- 최적화 프로그램은 손실 함수를 최소화하기 위해 모델 매개변수를 조정합니다. PyTorch의 torch.optim 모듈에는 SGD 및 Adam과 같은 다양한 최적화 알고리즘이 포함되어 있습니다.\n","\n","[ 모델 훈련 ]\n","- 훈련에는 데이터세트 반복, 모델 예측, 손실 계산, 모델 매개변수 업데이트가 포함됩니다.\n","\n","[ 모델 평가 ]\n","- 훈련 후에는 검증 또는 테스트 세트에서 모델의 성능을 평가하여 모델이 잘 일반화되는지 확인합니다."],"metadata":{"id":"vm8RHOwxGSFB"}},{"cell_type":"markdown","source":["https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html"],"metadata":{"id":"jZC-cKL0uohE"}},{"cell_type":"markdown","metadata":{"id":"BIN89DvVmOEa"},"source":["파이토치(PyTorch)에는 데이터 작업을 위한 기본 요소 두가지인\n","torch.utils.data.DataLoader 와 torch.utils.data.Dataset 가 있습니다.\n","Dataset 은 샘플과 정답(label)을 저장하고, DataLoader 는 Dataset 을 순회 가능한 객체(iterable)로 감쌉니다.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jN3leqy4mOEc","executionInfo":{"status":"ok","timestamp":1707956329618,"user_tz":-540,"elapsed":7700,"user":{"displayName":"한정현","userId":"04742589720279403748"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"]},{"cell_type":"markdown","source":["#### 데이터셋 불러오기\n","TorchVision 에서 Fashion-MNIST 데이터셋을 불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다. 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.\n","\n","다음 매개변수들을 사용하여 FashionMNIST 데이터셋 을 불러옵니다:\n","- root 는 학습/테스트 데이터가 저장되는 경로입니다.\n","- train 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.\n","- download=True 는 root 에 데이터가 없는 경우 인터넷에서 다운로드합니다.\n","- transform 과 target_transform 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다."],"metadata":{"id":"tddUl76dp71B"}},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kdn_ltOpIyv6","executionInfo":{"status":"ok","timestamp":1707956456919,"user_tz":-540,"elapsed":3,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"f3a60440-1c50-4ddb-a5a6-396fe8e8599d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!ls\n","# sample_data는 코랩에서 기본적으로 제공함"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b3SS0wrI0lj","executionInfo":{"status":"ok","timestamp":1707956459158,"user_tz":-540,"elapsed":4,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"81acf7f9-0ab2-440b-c747-e2521d2213dd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}]},{"cell_type":"code","source":["# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n","test_data = datasets.FashionMNIST(\n","    root='data',\n","    train=False,\n","    download=True,\n","    transform=ToTensor(), # 이미지를 PyTorch 텐서로 변환하는 전처리 단계를 지정\n",")\n","# train x,y , test x,y 는 자동으로 생성\n","# data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw -> train X 데이터가 이곳에 저장\n","# data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw -> train y 데이터가 이곳에 저장\n","# data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw -> test X 데이터가 이곳에 저장\n","# data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw -> test y 데이터가 이곳에 저장"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGwh2cnXJRxb","executionInfo":{"status":"ok","timestamp":1707956673978,"user_tz":-540,"elapsed":4823,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"34e13ee8-80d1-431e-c420-d71e7f5d63c3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 18562438.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 342342.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 6208780.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 15088942.69it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["training_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEfjR9QGJq7b","executionInfo":{"status":"ok","timestamp":1707956692466,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"faeec37a-c555-469b-f011-c2974cb8c1f4"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset FashionMNIST\n","    Number of datapoints: 60000\n","    Root location: data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["!ls\n","# data 가 생긴 모습..\n","# data 폴더 안에는 FashionMNIST 가 있음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQrZ5p0QJuGm","executionInfo":{"status":"ok","timestamp":1707956696518,"user_tz":-540,"elapsed":362,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"e2ae8cbb-6fee-4b30-cb87-ef0422949473"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["data  sample_data\n"]}]},{"cell_type":"code","source":["!ls data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJhsihj1KppE","executionInfo":{"status":"ok","timestamp":1707956975279,"user_tz":-540,"elapsed":401,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"b0c84c7e-da9f-4de6-e99f-ccb8874caed8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["FashionMNIST\n"]}]},{"cell_type":"code","source":["!pwd\n","# 마운팅을 안했기 때문에 /content 로 나옴 -> 구글 드라이브가 아니라 colab 자체임. /content 안에 data, sample_data 가 있음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZlINHFNKzGd","executionInfo":{"status":"ok","timestamp":1707956976916,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"26180ae7-10ae-44d9-8392-ad22d8b8b2ca"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["training_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFXEiNv9Gxba","executionInfo":{"status":"ok","timestamp":1707957221729,"user_tz":-540,"elapsed":365,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"87655f0b-8bf2-4f78-f303-b72f6ca09c43"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset FashionMNIST\n","    Number of datapoints: 60000\n","    Root location: data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["#### 데이터셋을 순회하고 시각화하기\n","Dataset 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: training_data[index]. matplotlib 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다."],"metadata":{"id":"kfrDHEu3rFT6"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","labels_map = {\n","    0: \"T-Shirt\",\n","    1: \"Trouser\",\n","    2: \"Pullover\",\n","    3: \"Dress\",\n","    4: \"Coat\",\n","    5: \"Sandal\",\n","    6: \"Shirt\",\n","    7: \"Sneaker\",\n","    8: \"Bag\",\n","    9: \"Ankle Boot\",\n","}\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3"],"metadata":{"id":"kDBSM6utNNct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# labels_map은 FashionMNIST 문서에서 가져온것이고 종류는 10가지 임\n","labels_map = {\n","    0: \"T-Shirt\",\n","    1: \"Trouser\",\n","    2: \"Pullover\",\n","    3: \"Dress\",\n","    4: \"Coat\",\n","    5: \"Sandal\",\n","    6: \"Shirt\",\n","    7: \"Sneaker\",\n","    8: \"Bag\",\n","    9: \"Ankle Boot\",\n","}\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","for i in range(1, cols * rows + 1): # 9개의 이미지를 위한 반복문을 시작\n","    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n","    # item()은 학습 데이터 세트의 길이 내에서 무작위 인덱스를 생성하고 무작위로 이미지 하나를 선택\n","    # training_data 는 6만개.\n","    img, label = training_data[sample_idx]\n","    figure.add_subplot(rows, cols, i) # 현재의 서브플롯(이미지가 표시될 위치)을 3x3 그리드에서 i번째 위치로 설정\n","    plt.title(labels_map[label])\n","    plt.axis(\"off\") # 여기서 축은 필요없으니까 off로 함\n","    # Matplotlib은 기본 컬러맵을 사용하여 이미지를 표현. 기본 컬러맵은 viridis\n","    plt.imshow(img.squeeze(), cmap=\"gray\") # img.squeeze()로 차원을 축소하여 plt.imshow() 함수에 적합한 2D 형태로 만든다.\n","    # cmap='gray' 하면 흑백으로.. 근데 기본은 형광임.\n","    # 28 by 28로 이미지를 출력하게끔..img.squeeze()는 이미지의 차원을 축소시키는데 사용됩니다 (예: 1x28x28에서 28x28로).\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"id":"vmdoBXC6q2qA","executionInfo":{"status":"ok","timestamp":1707958121304,"user_tz":-540,"elapsed":1641,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"db280db6-f508-47d4-c3d8-d7dd73e76de9"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 9 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["DataLoader는 배치 사이즈에 따라 데이터를 배치로 나누고, 모델 학습이나 평가 시에 데이터를 효율적으로 로드할 수 있도록 도와줍니다."],"metadata":{"id":"cp-g_f7ySpYN"}},{"cell_type":"markdown","metadata":{"id":"ZK3C5jZFmOEd"},"source":[" PyTorch의 DataLoader를 사용하여 학습 데이터(training_data)와 테스트 데이터(test_data)를 배치로 로딩하고, 테스트 데이터로더에서 첫 번째 배치의 형태(shape)와 데이터 타입을 출력하는 과정\n","\n","Dataset 을 DataLoader 의 인자로 전달합니다. 이는 데이터셋을 순회 가능한 객체(iterable)로 감싸고, 자동화된 배치(batch), 샘플링(sampling),\n","섞기(shuffle) 및 다중 프로세스로 데이터 불러오기(multiprocess data loading)를 지원합니다. 여기서는 배치 크기(batch size)를 64로 정의합니다.\n","즉, 데이터로더(dataloader) 객체의 각 요소는 64개의 특징(feature)과 정답(label)을 묶음(batch)으로 반환합니다.\n","\n"]},{"cell_type":"code","source":["60000 / 64\n","# 가중치가 어떻게 업데이트되나?\n","# 배치단위로 가중치 업데이트됨. 배치사이즈가 64이면 64개가 되고나서 한번에 가중치 업데이트됨.\n","# 스텝별로 가중치 업데이트가 됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1MRwnDzSyoP","executionInfo":{"status":"ok","timestamp":1707959076354,"user_tz":-540,"elapsed":365,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"7eddba8a-aa4e-45e0-f1cf-8b487234b723"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["937.5"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Tduo6QjemOEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707964143102,"user_tz":-540,"elapsed":323,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"06e05741-765a-4f56-a046-e9fd84f749b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}],"source":["batch_size = 64\n","\n","# 데이터로더를 생성합니다.\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\") # [N, C, H, W]는 일반적으로 이미지 데이터의 차원. 각각 배치 크기(N), 채널 수(C), 높이(H), 너비(W)를 의미\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"]},{"cell_type":"markdown","metadata":{"id":"bblODOgemOEe"},"source":["## 모델 만들기\n","PyTorch에서 신경망 모델은 nn.Module을 상속받는 클래스(class)를 생성하여 정의합니다. ``__init__`` 함수에서 신경망의 계층(layer)들을 정의하고 ``forward`` 함수에서 신경망에 데이터를 어떻게 전달할지 지정합니다. 가능한 경우 GPU로 신경망을 이동시켜 연산을 가속(accelerate)합니다.\n","\n"]},{"cell_type":"markdown","source":["#### 학습을 위한 장치 얻기\n","가능한 경우 GPU와 같은 하드웨어 가속기에서 모델을 학습하려고 합니다. torch.cuda가 사용 가능한지 확인해보고, 그렇지 않으면 CPU를 계속 사용합니다.\n","\n","#### 클래스 정의하기\n","신경망 모델을 nn.Module 의 하위클래스로 정의하고, __init__ 에서 신경망 계층들을 초기화합니다. nn.Module 을 상속받은 모든 클래스는 forward 메소드에 입력 데이터에 대한 연산들을 구현합니다."],"metadata":{"id":"arZkY8-4t5c2"}},{"cell_type":"code","source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dg-s7HXUXmpN","executionInfo":{"status":"ok","timestamp":1707964145054,"user_tz":-540,"elapsed":450,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"0de54289-de6f-4eb9-c46f-a4f66d79ffb1"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","execution_count":34,"metadata":{"id":"YezJAG5fmOEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707964146596,"user_tz":-540,"elapsed":525,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"4c4054b5-0a59-40e9-d14e-8b2763309bc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["# 학습에 사용할 CPU나 GPU, MPS 장치를 얻습니다.\n","# 코드를 보면.. pytorch는 pythonic함.(객체지향)\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","# 모델을 정의합니다.\n","class NeuralNetwork(nn.Module): # nn.Module을 상속받아 정의\n","    def __init__(self):\n","        super().__init__() # 메소드 내에서 모델의 레이어들이 초기화\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512), # 행렬곱. 가중치 계산해서 들어갈것임. 512는 출력\n","            nn.ReLU(), # 비선형. 0보다작으면 0 0보다크면 자신으로.. relu가 비활성화 하는 역할\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","            # linear 쓰다가 relu 쓰는 이유.. 선형만 쓰게되면 한계가 있음.\n","            # 비선형 변환을 위해서 일반화의외의 다른것들을 하기위해서 하는것임.\n","            # 보통 레이어가 복잡하면 복잡할수록 어려운것을 할 수 있음.(뇌 세포가 많으면 어려운 문제 해결할수 있는것처럼)\n","            # 물론 과적합안되게끔 컨트롤 해야함.\n","            # 입력사이즈가 지금은 별로 의미 없으니까 512 512를 10개 해도됨. 굳이 안줄여도됨. 가중치를 크게 해서 거르는거니까..\n","            # 숫자를 줄여간다는 것을 의무감처럼 생각할 필요 없고 레이어를 많이하면 됨.\n","        )\n","\n","    def forward(self, x): # 모델이 입력 데이터를 받아 출력까지 어떻게 처리할지를 정의\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)\n","# 출력했을때, bias=True는 편차(b)가 있다 라는 뜻.. 계산할때 편차 적용된다라는 의미임"]},{"cell_type":"markdown","metadata":{"id":"c9l2LtQtmOEg"},"source":["## 모델 매개변수 최적화하기\n","모델을 학습하려면 손실 함수(loss function)와\n","옵티마이저(optimizer)가 필요합니다.\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"rl_7bcAumOEg","executionInfo":{"status":"ok","timestamp":1707964148913,"user_tz":-540,"elapsed":477,"user":{"displayName":"한정현","userId":"04742589720279403748"}}},"outputs":[],"source":["# nn.CrossEntropyLoss()는 내부적으로 소프트맥스 계산을 포함. 모델의 출력 레이어에서 별도로 소프트 맥스를 적용할 필요가 없습니다.\n","# sigmoid 쓸때에는 다른 손실함수가 있음.\n","loss_fn = nn.CrossEntropyLoss() # 비용함수. LossFunction.\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # lr=0.001(아주 작은수를 넣었음)"]},{"cell_type":"markdown","metadata":{"id":"EiwUMtNJmOEg"},"source":["- 각 학습 단계(training loop)에서 모델은 (배치(batch)로 제공되는) 학습 데이터셋에 대한 예측을 수행하고,\n","예측 오류를 역전파하여 모델의 매개변수를 조정합니다.\n","- optimizer.zero_grad() 호출은 가중치(파라미터) 자체를 0으로 만드는 것이 아니라, 가중치의 기울기(gradient. 가중치 편미분해서 순간변화율 구하고 어느 방향 갈지.. 0일때 가장 손실이 적기때문에 0으로 초기화하는데,그리고 이전에 했던것들이 영향을 줄수 있기때문에 초기화하는 과정이필요함. 즉 0 에가까울때 가중치가 뭐냐를 찾는 것임(파라미터))를 0으로 초기화하는 과정이며 이는 각 배치마다 독립적으로 기울기를 계산할 수 있게 하여, 가중치 업데이트가 정확하게 이루어지도록 돕습니다.\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"mK8eqYyxmOEg","executionInfo":{"status":"ok","timestamp":1707964149921,"user_tz":-540,"elapsed":1,"user":{"displayName":"한정현","userId":"04742589720279403748"}}},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device) # device한것은 gpu쓰겠다(cuda)\n","\n","        # 예측 오류 계산\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        # 배치단위로 비용이 구해짐!(스텝별로..) --> 데이터포인트별로 되는게 아님.\n","\n","        # 역전파\n","        optimizer.zero_grad() # 전 배치에서 계산된 그래디언트를 0으로 초기화. 그전에것이 남아 있으면 왜곡이 발생할 수 있어서 초기화.\n","        # 그래디언트를 0으로 초기화하는것이지 가중치를 초기화하는 것이 아님.\n","        # forward로 가중치 계산. 그것을 backward로 역전파를 함\n","        loss.backward()\n","        # 가중치별로 편미분해서 배치단위로 업데이트 함\n","        optimizer.step()\n","\n","        if batch % 100 == 0: # 전부 표시하긴 그러니까 100개단위로 출력하기\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            # item은 뽑기. batch에 1더한것은 for문에 보면.. 0부터 시작할 수 있으니 +1 함\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","            # loss:>7f는 손실 값(loss)을 오른쪽 정렬로, 최소 7자리의 너비를 가진 부동소수점 숫자로 출력"]},{"cell_type":"markdown","metadata":{"id":"00Ep8P-vmOEh"},"source":["모델이 학습하고 있는지를 확인하기 위해 테스트 데이터셋으로 모델의 성능을 확인합니다.\n","\n"]},{"cell_type":"code","source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"qoXaQxc0mTuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":37,"metadata":{"id":"bO4UuC-8mOEh","executionInfo":{"status":"ok","timestamp":1707964151353,"user_tz":-540,"elapsed":1,"user":{"displayName":"한정현","userId":"04742589720279403748"}}},"outputs":[],"source":["def test(dataloader, model, loss_fn): # 테스트하는거니까 최적화(optimizer)는 필요없어서 안함\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval() # 평가함수는 model.eval()을 사용\n","    test_loss, correct = 0, 0\n","    with torch.no_grad(): # 학습이아니라 평가하는거라서 no_grad()를 사용. 가중치 업데이트 하는것이 목적이아니라서..\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            # 예측값중 가장 높은 인덱스(0-9중에 모델이 가장 확신하는 숫자)와 실제값이 일치하는 요소의 개수를 합산한 값(sum)을 숫자로 변환하여\n","            # correct에 추가\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 여기서 type은 float아니라 int로 해도됨. 왜냐면 개수는 다 정수니까..\n","            # pred.argmax(1) == y 는 0에서 9까지 분류한것을 맞춘것. 10개중에 가장 큰거 중에 하나를 반환하는 것.\n","    test_loss /= num_batches # 배치별 평균 손실\n","    correct /= size # 정확도가 나옴\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","    # 출력을 백분률.(100곱함) 자릿수. 오른쪽정렬 설정"]},{"cell_type":"markdown","metadata":{"id":"ViS450ZwmOEh"},"source":["학습 단계는 여러번의 반복 단계 (*에폭(epochs)*) 를 거쳐서 수행됩니다. 각 에폭에서는 모델은 더 나은 예측을 하기 위해  매개변수를 학습합니다.\n","각 에폭마다 모델의 정확도(accuracy)와 손실(loss)을 출력합니다; 에폭마다 정확도가 증가하고 손실이 감소하는 것을 보려고 합니다.\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"MUZO72fxmOEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707964269870,"user_tz":-540,"elapsed":118147,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"c562bd77-801d-4f43-b8dd-8bb5011154d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.296077  [   64/60000]\n","loss: 2.285810  [ 6464/60000]\n","loss: 2.272870  [12864/60000]\n","loss: 2.264748  [19264/60000]\n","loss: 2.243318  [25664/60000]\n","loss: 2.216516  [32064/60000]\n","loss: 2.219172  [38464/60000]\n","loss: 2.188477  [44864/60000]\n","loss: 2.188949  [51264/60000]\n","loss: 2.156931  [57664/60000]\n","Test Error: \n"," Accuracy: 40.8%, Avg loss: 2.151450 \n","\n","Epoch 2\n","-------------------------------\n","loss: 2.154909  [   64/60000]\n","loss: 2.150592  [ 6464/60000]\n","loss: 2.098852  [12864/60000]\n","loss: 2.114712  [19264/60000]\n","loss: 2.060320  [25664/60000]\n","loss: 2.002154  [32064/60000]\n","loss: 2.022926  [38464/60000]\n","loss: 1.951760  [44864/60000]\n","loss: 1.962135  [51264/60000]\n","loss: 1.881323  [57664/60000]\n","Test Error: \n"," Accuracy: 60.7%, Avg loss: 1.886612 \n","\n","Epoch 3\n","-------------------------------\n","loss: 1.913418  [   64/60000]\n","loss: 1.887083  [ 6464/60000]\n","loss: 1.779679  [12864/60000]\n","loss: 1.811445  [19264/60000]\n","loss: 1.692524  [25664/60000]\n","loss: 1.655484  [32064/60000]\n","loss: 1.656690  [38464/60000]\n","loss: 1.570068  [44864/60000]\n","loss: 1.600064  [51264/60000]\n","loss: 1.473912  [57664/60000]\n","Test Error: \n"," Accuracy: 62.7%, Avg loss: 1.503125 \n","\n","Epoch 4\n","-------------------------------\n","loss: 1.568800  [   64/60000]\n","loss: 1.531288  [ 6464/60000]\n","loss: 1.388825  [12864/60000]\n","loss: 1.448956  [19264/60000]\n","loss: 1.319272  [25664/60000]\n","loss: 1.336106  [32064/60000]\n","loss: 1.328006  [38464/60000]\n","loss: 1.263045  [44864/60000]\n","loss: 1.305404  [51264/60000]\n","loss: 1.191432  [57664/60000]\n","Test Error: \n"," Accuracy: 63.8%, Avg loss: 1.223706 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.299826  [   64/60000]\n","loss: 1.280416  [ 6464/60000]\n","loss: 1.117759  [12864/60000]\n","loss: 1.220540  [19264/60000]\n","loss: 1.089691  [25664/60000]\n","loss: 1.133356  [32064/60000]\n","loss: 1.138115  [38464/60000]\n","loss: 1.081420  [44864/60000]\n","loss: 1.128453  [51264/60000]\n","loss: 1.036794  [57664/60000]\n","Test Error: \n"," Accuracy: 65.0%, Avg loss: 1.060329 \n","\n","Done!\n"]}],"source":["epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")\n","# 60000 / 64 가 937.X 였음. 즉, 938개 나오는것을 100개단위로 나눠서 확인\n","# 64, 64*100 + 64(=6464), 64+200 + 64(=12864), ..."]},{"cell_type":"markdown","source":["PyTorch에서 모델을 저장하고 불러오는 표준 방법\n","\n","전체 모델 저장 및 로드하기:\n","- PyTorch에서는 torch.save()를 사용하여 전체 모델을 저장할 수 있으며, torch.load()로 모델을 불러올 수 있습니다. 이 방법은 모델의 구조와 모델의 매개변수를 모두 저장합니다. 하지만, 이 방법은 권장되지 않는 경우가 많습니다. 모델 클래스의 정의가 변경되면, 저장된 모델을 불러올 때 문제가 발생할 수 있기 때문입니다.\n","- 모델의 state_dict 저장 및 로드하기 (권장 방법):\n","모델의 매개변수(가중치와 편향)만 저장하는 것이 일반적이며 권장되는 방법입니다. 이 방법은 모델의 구조는 저장하지 않고, 매개변수만 저장합니다. 모델을 로드할 때는 먼저 모델의 인스턴스를 생성하고 state_dict를 로드합니다.\n","- 체크포인트 저장하기:\n","학습 중에 모델의 state_dict 뿐만 아니라, 옵티마이저의 state_dict, 에폭 번호, 최고 기록 등과 같은 추가 정보를 저장할 수 있습니다. 이 방법은 학습 과정을 중단했다가 다시 시작할 때 유용합니다. 확장자는 .pth\n","- ONNX 형식으로 내보내기:\n","PyTorch 모델을 다른 프레임워크에서 사용할 수 있도록 Open Neural Network Exchange(ONNX) 형식으로 내보낼 수 있습니다. 이 방법은 PyTorch 외의 다른 환경에서 모델을 배포할 때 유용합니다.\n",".pth 또는 .pt 파일로 state_dict을 저장하는 것이 가장 일반적이고 권장되는 방법입니다. 이 방법은 모델의 가벼운 매개변수만 저장하며, 모델 구조의 변경에 유연하게 대응할 수 있게 해줍니다. 다만, 모델을 로드할 때는 저장할 때 사용한 동일한 모델 클래스를 사용하여 인스턴스를 먼저 생성해야 합니다."],"metadata":{"id":"BPT2IzzOofdn"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CzTxAUxkJfOS","executionInfo":{"status":"ok","timestamp":1707964743490,"user_tz":-540,"elapsed":18290,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"e0533322-717b-4297-c8c8-fe46ae2f06c0"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"tNVUQjZrmOEi"},"source":["## 모델 저장하기\n","모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)을\n","직렬화(serialize)하는 것입니다.\n","\n"]},{"cell_type":"code","source":["# .pth 또는 .pt 파일로 state_dict을 저장하는 것이 가장 일반적이고 권장되는 방법\n","import os\n","# Define the save path\n","save_path = \"/content/drive/MyDrive/hjh_kita_directory/Github/kita_231026/m6_dl/data/model/model.pth\"\n","\n","# Ensure directory exists\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","# exist_ok = True 는 해당 경로의 디렉터리가 이미 존재할 경우 오류를 발생시키지 않고 넘어가도록 설정.\n","# 이미 해당 경로에 디렉터리가 존재해도 코드 실행 시 문제가 발생하지 않게끔 함. 즉 디렉터리가 없으면 생성 하는 것임"],"metadata":{"id":"E0HX9IWSoQn9","executionInfo":{"status":"ok","timestamp":1707965141169,"user_tz":-540,"elapsed":338,"user":{"displayName":"한정현","userId":"04742589720279403748"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","execution_count":41,"metadata":{"id":"PqX8T-9amOEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707965350256,"user_tz":-540,"elapsed":347,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"fdb81665-342f-4d3b-8952-ade8373d5688"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved PyTorch Model State to model.pth\n"]}],"source":["# 모델의 매개변수(가중치와 편향)만 저장\n","torch.save(model.state_dict(), save_path)\n","print(\"Saved PyTorch Model State to model.pth\")"]},{"cell_type":"markdown","metadata":{"id":"37CA-jq2mOEi"},"source":["## 모델 불러오기\n","\n","모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RGloKzoBmOEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732510151,"user_tz":-540,"elapsed":455,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"2624847c-993c-4967-e335-6e5622bee487"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}],"source":["model = NeuralNetwork().to(device) # 저장할 때 사용한 동일한 모델 클래스를 사용하여 인스턴스를 먼저 생성\n","model.load_state_dict(torch.load(save_path))"]},{"cell_type":"markdown","metadata":{"id":"DcPNshIwmOEi"},"source":["이제 이 모델을 사용해서 예측을 할 수 있습니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1W6E7bYmOEj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732519681,"user_tz":-540,"elapsed":430,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"9592a215-1862-45cb-bad0-23906a67a992"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}],"source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval() # 평가(evaluation) 모드로 설정\n","x, y = test_data[0][0], test_data[0][1] # 테스트 데이터셋에서 첫 번째 샘플(이미지)과 그에 해당하는 레이블을 가져옵니다.\n","with torch.no_grad(): # 평가 또는 추론 시에는 모델을 업데이트할 필요가 없으므로 그라디언트를 계산할 필요가 없습니다.\n","    x = x.to(device) # 테스트 샘플을 현재 설정된 장치(CPU 또는 GPU)로 이동\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y] # 모델의 예측 결과 중 가장 높은 값을 가지는 인덱스와 실제 레이블에 해당하는 클래스의 이름\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"]},{"cell_type":"markdown","source":["- torch: 이것은 메인 PyTorch 라이브러리입니다. 여기에는 GPU를 통한 가속을 통한 텐서 계산 지원, 신경망 훈련을 용이하게 하는 자동 차별화, 모델 구축 및 훈련을 위한 다양한 유틸리티가 포함됩니다.\n","- torch.nn: 레이어, 활성화 함수, 손실 함수와 같은 신경망의 구성 요소를 제공하는 PyTorch의 하위 모듈입니다. 신경망의 아키텍처를 정의하는 데 필수적입니다.\n","- torch.nn.function: 이 모듈에는 torch.nn 레이어에서 사용되는 기능이 포함되어 있습니다. 입력 데이터 및 가중치에 이러한 함수를 직접 사용할 수 있으므로 일부 작업에 더 많은 유연성을 제공합니다. 여기에는 활성화, 손실 계산 및 상태(즉, 가중치)를 유지하지 않는 다양한 기타 작업을 위한 함수가 포함됩니다.\n","- torch.optim: 이 하위 모듈은 SGD(Stochastic Gradient Descent), Adam 등과 같은 신경망 훈련을 위한 최적화 알고리즘을 제공합니다. 이러한 최적화 프로그램은 계산된 기울기를 기반으로 네트워크의 가중치를 업데이트하는 데 사용됩니다.\n","- torchvision: 이미지 데이터 작업을 위한 유틸리티를 제공하는 PyTorch 프로젝트의 패키지입니다. 여기에는 사전 정의된 데이터세트(예: MNIST, CIFAR10, FashionMNIST), 모델 아키텍처(예: ResNet, AlexNet) 및 전처리를 위한 일반적인 이미지 변환이 포함됩니다.\n","- torchvision.transforms: 일반적인 이미지 변환을 제공하는 torchvision 내의 모듈입니다. 이는 이미지를 신경망에 공급하기 전에 데이터 증대 및 이미지 전처리에 사용될 수 있습니다. 예로는 크기 조정, 정규화, 텐서로 변환 등이 있습니다.\n","- SubsetRandomSampler: 교체 없이 데이터세트에서 요소를 무작위로 샘플링하는 데 사용되는 도구입니다. 데이터 세트를 훈련 및 검증/테스트 세트로 분할하거나 모델 훈련을 위해 사용자 정의 데이터 샘플링 전략을 구현하려는 경우에 특히 유용"],"metadata":{"id":"PDn0y07kIKnU"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"}},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 사이킷런의 model_selection 모듈\n","model_selection 모듈은 머신러닝 모델을 개발하고 평가하는 데 유용한 도구입니다. model_selection 모듈을 사용하면 데이터를 더 잘 이해하고 더 나은 모델을 개발할 수 있습니다.\n","- 학습 데이터와 테스트 데이터를 분리하거나 교차 검증, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위해서 다양한 함수와 클래스를 제공합니다.\n","\n","- 학습 데이터와 테스트 데이터를 분리하는 방법에는 여러 가지가 있습니다. 가장 일반적인 방법은 train_test_split() 함수를 사용하는 것입니다. train_test_split() 함수는 학습 데이터와 테스트 데이터를 70:30의 비율로 분리합니다.\n","\n","- 교차 검증은 모델의 성능을 평가하는 방법입니다. 교차 검증은 데이터를 여러 개의 폴드로 분리한 다음 각 폴드를 테스트 데이터로 사용하고 나머지 폴드를 학습 데이터로 사용하여 모델을 학습하는 방법입니다. 교차 검증은 모델의 성능을 더 정확하게 평가할 수 있습니다.\n","\n","- Estimator의 하이퍼 파라미터를 튜닝하는 방법에는 여러 가지가 있습니다. 가장 일반적인 방법은 GridSearchCV() 함수를 사용하는 것입니다. GridSearchCV() 함수는 주어진 하이퍼 파라미터의 모든 조합에 대해 모델을 학습하고 평가하여 가장 좋은 하이퍼 파라미터를 찾습니다.\n"],"metadata":{"id":"GXot3h_gYpzw"}},{"cell_type":"markdown","source":["## 학습/테스트 데이터 셋 분리 - train_test_split()\n","- 첫 번째 파라미터로 피처 데이터 세트, 두 번째 파라미터로 레이블 데이터 세트를 입력받음. (8:2 혹은 7:3이 가장 일반적)\n","- 선택적 파라미터로 test_size(기본값은 0.25), shuffle(기본값은 True), random_state를 입력받음.\n","- train_test_split()의 반환값은 튜플 형태임."],"metadata":{"id":"f1tUc_5eY2GQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zA1MuS5bYPsY","executionInfo":{"status":"ok","timestamp":1706149010592,"user_tz":-540,"elapsed":309,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"a0e823f5-89b0-494e-8b7b-2ea159c15e2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["예측 정확도: 1.0\n"]}],"source":["from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","iris = load_iris()\n","dt_clf = DecisionTreeClassifier()\n","train_data = iris.data\n","train_label = iris.target\n","dt_clf.fit(train_data, train_label)\n","\n","# 학습 데이터 셋으로 예측 수행\n","pred = dt_clf.predict(train_data)\n","print('예측 정확도:',accuracy_score(train_label,pred))"]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","dt_clf = DecisionTreeClassifier( )\n","iris_data = load_iris()\n","\n","X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=10)\n","\n","dt_clf.fit(X_train, y_train)\n","pred = dt_clf.predict(X_test)\n","print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqUXWfKwZ_SK","executionInfo":{"status":"ok","timestamp":1706149034751,"user_tz":-540,"elapsed":320,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"173e72ab-8e4e-4b20-93e6-7121c619219e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["예측 정확도: 0.9778\n"]}]},{"cell_type":"markdown","source":["## 교차 검증 기술\n","- 기계 학습 모델을 학습할 때 학습 데이터에서 학습된 패턴을 기반으로 새로운 보이지 않는 데이터에 대해 정확한 예측을 할 수 있는 모델을 만들려고 합니다. 문제는 모델을 실제로 테스트하기 전에는 본 적이 없는 데이터에서 모델이 얼마나 잘 작동할지 알 수 없다는 것입니다.\n","- 교차 유효성 검사에는 전체 데이터 세트를 모델 훈련을 위한 더 큰 섹션과 모델 테스트를 위한 더 작은 섹션의 두 섹션으로 나누는 작업이 포함됩니다.\n","- '트레이닝 세트'는 데이터의 기본 패턴에 대해 모델을 가르치는 데 사용됩니다. 반면 '테스트 세트'는 모델이 이러한 패턴을 얼마나 잘 학습했는지 평가하는 데 사용됩니다. 모델은 교육 중에 테스트 데이터를 본 적이 없으므로 테스트 세트는 '보이지 않는 새로운 데이터'로 작동합니다.\n","- 이제 이 작은 부분(테스트 세트)에서 모델을 테스트할 때 얻은 \"점수\"는 모델이 미래에 실제 보이지 않는 데이터에서 얼마나 잘 수행될 것인지에 대한 추정치로 사용됩니다.\n","- 서로 다른 데이터 하위 집합(교차 유효성 검사의 핵심)에 대해 이 프로세스를 여러 번 반복함으로써 새 데이터로 일반화하는 모델의 능력에 대해 보다 신뢰할 수 있는 추정치를 얻습니다.\n","- 즉, 대부분의 데이터(훈련 세트)에서 모델을 훈련한 다음 데이터의 작은 부분(테스트 세트)에서 테스트함으로써 모델이 얼마나 잘 수행될 가능성이 있는지 보다 정확한 측정값을 얻을 수 있습니다. 완전히 새로운 데이터를 만나면 수행합니다."],"metadata":{"id":"8fOZrU9mbdy7"}},{"cell_type":"markdown","source":["## 교차 검증이 필요한 이유\n","\n","- 교차 유효성 검사는 독립적인 데이터 세트에서 모델의 성능을 평가하고 과적합을 방지하기 위해 기계 학습에 사용되는 통계 기법으로 다음과 같은 이유로 중요합니다.\n","    - 과적합: 과적합은 모델이 노이즈나 이상값을 포함하여 훈련 데이터를 너무 잘 학습할 때 발생합니다. 이러한 경우 모델은 학습 데이터에 대해 뛰어난 정확도를 갖지만 학습시 보이지 않는 데이터(학습시 사용하지 않았던 데이터, 실 데이터 등)에 대해서는 성능이 저하될 수 있습니다. 교차 검증은 보다 일반화된 성능 메트릭을 제공하여 과적합을 방지하는 데 도움이 됩니다.\n","    - 하이퍼파라미터 조정: 교차 검증은 일반적으로 그리드 검색 또는 기타 하이퍼파라미터 튜닝 방법과 함께 사용되어 최상의 성능을 가진 모델을 생성하는 하이퍼파라미터를 찾습니다.\n","    - 모델 비교: 여러 모델을 비교할 때 교차 검증은 서로 다른 데이터 하위 집합의 성능을 평균화하므로 보다 신뢰할 수 있는 비교를 제공하는 데 도움이 됩니다.\n","\n","- 교차 검증 방법 : k-겹 교차 검증\n","    - 데이터세트 분할: 전체 데이터세트를 'k'개의 동일한 부분(또는 '접기')으로 나눕니다. (즉, k=5를 선택한다면 데이터를 5개의 하위 집합으로 나눔.)\n","    - 훈련 및 테스트: 하나의 하위 집합을 테스트 세트로 유지하고, 나머지 k-1개의 하위 집합에서 모델을 훈련합니다.\n","    - 평가: 테스트 세트에서 모델의 성능 메트릭(예: 문제에 따라 정확도, 정밀도, 재현율, F1 점수 등)을 계산합니다.\n","    - 반복: 이 프로세스를 k번 반복합니다. 매번 다른 하위 집합을 테스트 세트로 사용하고 나머지 하위 집합을 훈련 세트로 사용합니다.\n","    - 평균 성능: k 반복에 대한 성능 메트릭의 평균을 계산합니다. 이는 모델의 교차 유효성 검사 점수로, 성능에 대한 보다 일반화된 척도를 제공합니다.\n","\n","- 교차 유효성 검사의 기본 아이디어는 학습용 데이터에 대해 학습하고 검증용 데이터로 테스트할 때 얻은 \"점수\"가 새로운 데이터에서 모델이 수행되는 방식을 나타낼 가능성을 더 높다는 것입니다.\n","- Python에서는 sklearn.model_selection 모듈의 cross_val_score 함수를 사용하여 교차 검증을 쉽게 수행할 수 있습니다."],"metadata":{"id":"kIdAmsNnZzMk"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","\n","import numpy as np\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","features = iris.data\n","label = iris.target\n","dt_clf = DecisionTreeClassifier(random_state = 156)\n","\n","# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n","kfold = KFold(n_splits = 5)\n","cv_accuracy = []\n","\n","print('붓꽃 데이터 세트의 크기 :', features.shape[0], '\\n')\n","features[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kT-gFO2ccWeN","executionInfo":{"status":"ok","timestamp":1706185222890,"user_tz":-540,"elapsed":342,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"6c65bdf1-65c6-4e61-82c3-dff8d6d302f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["붓꽃 데이터 세트의 크기 : 150 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[5.1, 3.5, 1.4, 0.2],\n","       [4.9, 3. , 1.4, 0.2],\n","       [4.7, 3.2, 1.3, 0.2]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["n_iter = 0\n","\n","# KFold 객체의 split() 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n","for train_index, test_index in kfold.split(features):\n","  # kfold.split()으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","  X_train, X_test = features[train_index], features[test_index]\n","  y_train, y_test = label[train_index], label[test_index]\n","\n","  # 학습 및 예측\n","  dt_clf.fit(X_train, y_train)\n","  pred = dt_clf.predict(X_test)\n","  n_iter += 1\n","  print(\"실재 사실:\", y_test)\n","  print(\"예측한 것:\", pred)\n","  # 반복시마다 정확도 측정\n","  accuracy = np.round(accuracy_score(y_test, pred), 4)\n","  train_size = X_train.shape[0]\n","  test_size = X_test.shape[0]\n","\n","  print('\\n [# {0}] 교차검증 정확도: {1}  /  학습 데이터 크기: {2}  /  검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n","  print(' [# {0}] 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n","  cv_accuracy.append(accuracy)\n","\n","# 각각의 iteration별 정확도를 합하여 평균 정확도 계산\n","print('\\n ## 평균 검증 정확도:', np.mean(cv_accuracy))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAD2Hvlbd4Eu","executionInfo":{"status":"ok","timestamp":1706177027137,"user_tz":-540,"elapsed":2,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"003a2eb1-6b3e-4460-b555-4dfe444bd544"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["실재 사실: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","예측한 것: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n"," [# 1] 교차검증 정확도: 1.0  /  학습 데이터 크기: 120  /  검증 데이터 크기: 30\n"," [# 1] 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29]\n","실재 사실: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n","예측한 것: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 1 1]\n","\n"," [# 2] 교차검증 정확도: 0.9667  /  학습 데이터 크기: 120  /  검증 데이터 크기: 30\n"," [# 2] 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n"," 54 55 56 57 58 59]\n","실재 사실: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","예측한 것: [1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1]\n","\n"," [# 3] 교차검증 정확도: 0.8667  /  학습 데이터 크기: 120  /  검증 데이터 크기: 30\n"," [# 3] 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n"," 84 85 86 87 88 89]\n","실재 사실: [1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","예측한 것: [1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1]\n","\n"," [# 4] 교차검증 정확도: 0.9333  /  학습 데이터 크기: 120  /  검증 데이터 크기: 30\n"," [# 4] 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n"," 108 109 110 111 112 113 114 115 116 117 118 119]\n","실재 사실: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","예측한 것: [2 2 2 1 2 2 1 1 2 1 2 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2]\n","\n"," [# 5] 교차검증 정확도: 0.7333  /  학습 데이터 크기: 120  /  검증 데이터 크기: 30\n"," [# 5] 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n"," 138 139 140 141 142 143 144 145 146 147 148 149]\n","\n"," ## 평균 검증 정확도: 0.9\n"]}]},{"cell_type":"code","source":["# Q. K값을 3으로 설정하여 각각 교차 검증을 수행\n","\n","kfold = KFold(n_splits = 3)\n","cv_accuracy = []\n","\n","n_iter = 0\n","\n","# KFold 객체의 split() 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n","for train_index, test_index in kfold.split(features):\n","  # kfold.split()으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","  X_train, X_test = features[train_index], features[test_index]\n","  y_train, y_test = label[train_index], label[test_index]\n","\n","  # 학습 및 예측\n","  dt_clf.fit(X_train, y_train)\n","  pred = dt_clf.predict(X_test)\n","  n_iter += 1\n","\n","  # 반복시마다 정확도 측정\n","  accuracy = np.round(accuracy_score(y_test, pred), 4)\n","  train_size = X_train.shape[0]\n","  test_size = X_test.shape[0]\n","\n","  print('\\n [# {0}] 교차검증 정확도: {1}  /  학습 데이터 크기: {2}  /  검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n","  print(' [# {0}] 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n","  cv_accuracy.append(accuracy)\n","\n","# 각각의 iteration별 정확도를 합하여 평균 정확도 계산\n","print('\\n ## 평균 검증 정확도:', np.mean(cv_accuracy))\n","\n","# 데이터의 쏠림 현상 때문에 검증 정확도가 모두 0이 나옴."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQah31ndg4xn","executionInfo":{"status":"ok","timestamp":1706151170236,"user_tz":-540,"elapsed":316,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"b11fec3c-411e-4fc5-d321-d314646c3a55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," [# 1] 교차검증 정확도: 0.0  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 1] 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"," 48 49]\n","\n"," [# 2] 교차검증 정확도: 0.0  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 2] 검증 세트 인덱스: [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n"," 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n"," 98 99]\n","\n"," [# 3] 교차검증 정확도: 0.0  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 3] 검증 세트 인덱스: [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n"," 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n"," 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n","\n"," ## 평균 검증 정확도: 0.0\n"]}]},{"cell_type":"markdown","source":["### **[코드의 실행결과 정리]**\n"," 붓꽃 데이터 세트는 150개의 데이터 포인트를 가지고 있으며, 각 클래스(붓꽃의 종류)마다 50개의 데이터 포인트가 있다. 이 데이터는 종류별로 정렬되어 있기 때문에, KFold로 단순히 처음부터 데이터를 3개의 폴드로 나누면, 각 폴드는 특정 종류의 붓꽃만을 포함하게 된다. 예를 들어, 첫 번째 폴드는 첫 번째 종류의 붓꽃만, 두 번째 폴드는 두 번째 종류의 붓꽃만 포함하게 되는 것이다.\n","\n","이런 분할 방식으로 인해 학습 데이터와 테스트 데이터가 완전히 다른 종류의 붓꽃만을 포함하게 되어, 모델이 적절히 학습되지 못하고 정확도가 0이 되는 결과를 초래"],"metadata":{"id":"TB7naVkN3ZAM"}},{"cell_type":"code","source":["# 데이터의 쏠림 현상을 막기 위하여 'StratifiedKFold'를 이용하여 각각 교차 검증을 수행\n","from sklearn.model_selection import StratifiedKFold\n","\n","import numpy as np\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","features = iris.data\n","label = iris.target\n","dt_clf = DecisionTreeClassifier(random_state = 156)\n","\n","# StratifiedKFold 사용\n","stratified_kfold = StratifiedKFold(n_splits = 3)\n","cv_accuracy = []\n","print('크기', features.shape[0])\n","\n","n_iter = 0\n","\n","# KFold 객체의 split() 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n","for train_index, test_index in stratified_kfold.split(features, label):\n","  # kfold.split()으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","  X_train, X_test = features[train_index], features[test_index]\n","  y_train, y_test = label[train_index], label[test_index]\n","\n","  # 학습 및 예측\n","  dt_clf.fit(X_train, y_train)\n","  pred = dt_clf.predict(X_test)\n","  n_iter += 1\n","\n","  # 반복시마다 정확도 측정\n","  accuracy = np.round(accuracy_score(y_test, pred), 4)\n","  train_size = X_train.shape[0]\n","  test_size = X_test.shape[0]\n","\n","  print('\\n [# {0}] 교차검증 정확도: {1}  /  학습 데이터 크기: {2}  /  검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n","  print(' [# {0}] 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n","  cv_accuracy.append(accuracy)\n","\n","# 각각의 iteration별 정확도를 합하여 평균 정확도 계산\n","print('\\n ## 평균 검증 정확도:', round(np.mean(cv_accuracy), 4))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdW_Bt-pjDy3","executionInfo":{"status":"ok","timestamp":1706192205452,"user_tz":-540,"elapsed":316,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"f43f90bc-c6a5-4f47-cdb9-a94c7a192de0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["크기 150\n","\n"," [# 1] 교차검증 정확도: 0.98  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 1] 검증 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n","  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n"," 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n","\n"," [# 2] 교차검증 정확도: 0.94  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 2] 검증 세트 인덱스: [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n","  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n"," 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n","\n"," [# 3] 교차검증 정확도: 0.98  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 3] 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n","  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n"," 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n","\n"," ## 평균 검증 정확도: 0.9667\n"]}]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","\n","import numpy as np\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","features = iris.data\n","label = iris.target\n","dt_clf = DecisionTreeClassifier(random_state = 156)\n","\n","# 'StratifiedKFold'가 아닌 'KFold'를 사용하면서 shuffle을 사용해서 값을 섞어줌\n","kfold = KFold(n_splits = 3, shuffle=True, random_state=42)\n","cv_accuracy = []\n","\n","print('붓꽃 데이터 세트의 크기 :', features.shape[0], '\\n')\n","features[:3]\n","\n","n_iter = 0\n","\n","# KFold 객체의 split() 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n","for train_index, test_index in kfold.split(features):\n","  # kfold.split()으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","  X_train, X_test = features[train_index], features[test_index]\n","  y_train, y_test = label[train_index], label[test_index]\n","\n","  # 학습 및 예측\n","  dt_clf.fit(X_train, y_train)\n","  pred = dt_clf.predict(X_test)\n","  n_iter += 1\n","\n","  # 반복시마다 정확도 측정\n","  accuracy = np.round(accuracy_score(y_test, pred), 4)\n","  train_size = X_train.shape[0]\n","  test_size = X_test.shape[0]\n","\n","  print('\\n [# {0}] 교차검증 정확도: {1}  /  학습 데이터 크기: {2}  /  검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n","  print(' [# {0}] 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n","  cv_accuracy.append(accuracy)\n","\n","# 각각의 iteration별 정확도를 합하여 평균 정확도 계산\n","print('\\n ## 평균 검증 정확도:', np.mean(cv_accuracy))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoW3YyRW14vW","executionInfo":{"status":"ok","timestamp":1706192421549,"user_tz":-540,"elapsed":345,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"29693cdf-04ba-4866-d34a-08a2cbeec8bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["붓꽃 데이터 세트의 크기 : 150 \n","\n","\n"," [# 1] 교차검증 정확도: 0.98  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 1] 검증 세트 인덱스: [  4   9  10  11  12  15  16  18  19  22  26  27  29  30  31  32  36  42\n","  45  51  55  56  64  65  68  69  73  75  76  78  81  82  85  86 104 108\n"," 109 110 118 127 128 131 132 133 137 141 142 143 145 146]\n","\n"," [# 2] 교차검증 정확도: 0.92  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 2] 검증 세트 인덱스: [  0   5   7   8  13  23  24  25  28  33  34  35  39  40  43  44  47  49\n","  53  60  62  66  67  70  77  80  83  84  89  93  94  95  96  97  98 101\n"," 105 111 113 114 117 119 120 122 123 125 134 135 138 148]\n","\n"," [# 3] 교차검증 정확도: 0.92  /  학습 데이터 크기: 100  /  검증 데이터 크기: 50\n"," [# 3] 검증 세트 인덱스: [  1   2   3   6  14  17  20  21  37  38  41  46  48  50  52  54  57  58\n","  59  61  63  71  72  74  79  87  88  90  91  92  99 100 102 103 106 107\n"," 112 115 116 121 124 126 129 130 136 139 140 144 147 149]\n","\n"," ## 평균 검증 정확도: 0.94\n"]}]},{"cell_type":"markdown","source":["### ** [ 'StratifiedKFold' vs 'Shuffle' ] **\n","- StratifiedKFold는 테스트 세트 내의 클래스의 비율을 유지하는 반면, Shuffle은 랜덤 발생이기에 테스트 세트 내의 클래스의 비율이 유지되지 않는다."],"metadata":{"id":"4ni_-iCJ3lL9"}},{"cell_type":"markdown","source":["### **[ stratify=y vs. StratifiedKFold ]**\n","\n","stratify=y:\n","\n","- stratify=y는 데이터를 훈련 세트와 테스트 세트로 분할할 때 클래스 비율을 유지하는 옵션. 이 옵션은 주로 train_test_split 함수와 같은 데이터 분할 함수에서 사용.\n","- stratify=y를 사용하면 원본 데이터의 클래스 비율을 훈련 세트와 테스트 세트에서도 유지할 수 있다. 예를 들어, 레이블이 0과 1인 두 클래스가 원본 데이터에서 각각 25%, 75%를 차지한다면, stratify=y 옵션을 사용하여 분할하면 훈련 세트와 테스트 세트에서도 각 클래스의 비율이 대략적으로 25%와 75%를 유지하게 된다.\n","\n","StratifiedKFold:\n","\n","- StratifiedKFold는 교차 검증을 수행할 때 각 폴드가 원본 데이터의 클래스 분포를 반영.\n","- StratifiedKFold는 k-폴드 교차 검증의 변형으로, 각 폴드에서의 클래스 비율이 전체 데이터 세트의 클래스 비율을 대표하도록 만든다.\n","- 이 방법은 주로 모델의 성능을 평가하거나 하이퍼파라미터를 튜닝할 때 사용되며, 데이터가 불균형할 경우 특히 유용. 예를 들어, 5-폴드 교차 검증을 사용할 경우, StratifiedKFold는 각 폴드가 전체 데이터의 클래스 비율을 유지하도록 보장.\n","\n","결론적으로, stratify=y는 단일 데이터 분할(훈련/테스트 세트 분할)에서 클래스 비율을 유지하는 데 사용되며, StratifiedKFold는 교차 검증에서 각 폴드의 클래스 비율을 유지하는 데 사용. 두 방법 모두 클래스 불균형을 고려하여 보다 신뢰할 수 있는 학습 및 평가를 가능하게 한다."],"metadata":{"id":"rwxPdGb63vZp"}},{"cell_type":"code","source":["# Stratified KFold\n","\n","import pandas as pd\n","\n","iris = load_iris()\n","\n","iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","iris_df['label'] = iris.target\n","iris_df['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ttnQ8w418PP","executionInfo":{"status":"ok","timestamp":1706192846191,"user_tz":-540,"elapsed":315,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"58bc488e-ae1e-4b60-a165-0e2fb2b8075a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    50\n","1    50\n","2    50\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### **[ KFold 문제점과 그에 따른 'StratifiedKFold' 사용 이유에 대한 예제 코드 ]**"],"metadata":{"id":"jh1Il_F66Wpo"}},{"cell_type":"code","source":["# KFold :: 학습 label은 모두 1,2이고 검증 label은 모두 3으로 arrange 될 수 있음\n","kfold = KFold(n_splits = 3)\n","\n","# 데이터 세트 반복에 따라 달라지는 학습/테스트용 데이터 로우 인덱스 번호 반환.\n","n_iter = 0\n","\n","for train_index, test_index in kfold.split(iris_df):\n","  n_iter += 1\n","\n","  label_train = iris_df['label'].iloc[train_index]\n","  label_test = iris_df['label'].iloc[test_index]\n","\n","  print('[# 교차검증 {0} ]\\n'.format(n_iter))\n","  print('학습 레이블 데이터 분포 :\\n', label_train.value_counts(), '\\n')\n","  print('검증 레이블 데이터 분포 :\\n', label_test.value_counts())\n","  print('-' * 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qg3vNjHN4sgt","executionInfo":{"status":"ok","timestamp":1706193408366,"user_tz":-540,"elapsed":327,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"76d8a943-7336-4001-fc59-0d5c2d46b29e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[# 교차검증 1 ]\n","\n","학습 레이블 데이터 분포 :\n"," 1    50\n","2    50\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 0    50\n","Name: label, dtype: int64\n","--------------------------------------------------\n","[# 교차검증 2 ]\n","\n","학습 레이블 데이터 분포 :\n"," 0    50\n","2    50\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 1    50\n","Name: label, dtype: int64\n","--------------------------------------------------\n","[# 교차검증 3 ]\n","\n","학습 레이블 데이터 분포 :\n"," 0    50\n","1    50\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 2    50\n","Name: label, dtype: int64\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["# StratifiedKFold :: 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배함\n","from sklearn.model_selection import StratifiedKFold\n","\n","skf = StratifiedKFold(n_splits = 3)\n","# 데이터 세트 반복에 따라 달라지는 학습/테스트용 데이터 로우 인덱스 번호 반환.\n","n_iter = 0\n","\n","for train_index, test_index in skf.split(iris_df, iris_df['label']):\n","  n_iter += 1\n","\n","  label_train = iris_df['label'].iloc[train_index]\n","  label_test = iris_df['label'].iloc[test_index]\n","\n","  print('[# 교차검증 {0} ]\\n'.format(n_iter))\n","  print('학습 레이블 데이터 분포 :\\n', label_train.value_counts(), '\\n')\n","  print('검증 레이블 데이터 분포 :\\n', label_test.value_counts())\n","  print('-' * 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-g_bjIH6PXH","executionInfo":{"status":"ok","timestamp":1706193321639,"user_tz":-540,"elapsed":405,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"2cf05347-cfe6-4666-904e-29d1019ce2f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[# 교차검증 1 ]\n","\n","학습 레이블 데이터 분포 :\n"," 2    34\n","0    33\n","1    33\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 0    17\n","1    17\n","2    16\n","Name: label, dtype: int64\n","--------------------------------------------------\n","[# 교차검증 2 ]\n","\n","학습 레이블 데이터 분포 :\n"," 1    34\n","0    33\n","2    33\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 0    17\n","2    17\n","1    16\n","Name: label, dtype: int64\n","--------------------------------------------------\n","[# 교차검증 3 ]\n","\n","학습 레이블 데이터 분포 :\n"," 0    34\n","1    33\n","2    33\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 1    17\n","2    17\n","0    16\n","Name: label, dtype: int64\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YFqxXt18DrlG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# [참고] Suffle ::: 데이터셋 내의 레이블이 균등하게 분포되지 않음.\n","# shuffle은 데이터셋 내의 레이블 분포를 균등하게 만들지는 않습니다. 즉, 클래스 불균형 문제를 해결하지는 못합니다.\n","# shuffle은 단지 데이터 포인트들을 무작위로 섞을 뿐, 각 클래스 내의 샘플 수를 변경하지 않습니다.\n","# 불균형한 데이터셋을 다룰 때는 StratifiedKFold가 더 적합합니다.\n","# StratifiedKFold는 각 클래스의 비율이 전체 데이터셋의 비율을 반영하도록 각 폴드를 구성하여, 각 클래스가 균등하게 대표되도록 합니다.\n","from sklearn.model_selection import KFold\n","\n","kfold = KFold(n_splits = 3, shuffle=True)\n","\n","# 데이터 세트 반복에 따라 달라지는 학습/테스트용 데이터 로우 인덱스 번호 반환.\n","n_iter = 0\n","\n","for train_index, test_index in kfold.split(iris_df):\n","  n_iter += 1\n","\n","  label_train = iris_df['label'].iloc[train_index]\n","  label_test = iris_df['label'].iloc[test_index]\n","\n","  print('[# 교차검증 {0} ]\\n'.format(n_iter))\n","  print('학습 레이블 데이터 분포 :\\n', label_train.value_counts(), '\\n')\n","  print('검증 레이블 데이터 분포 :\\n', label_test.value_counts())\n","  print('-' * 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cWydTEQ7Elx","executionInfo":{"status":"ok","timestamp":1706193660473,"user_tz":-540,"elapsed":308,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"c9dc15db-549a-4828-b715-973423b4c7f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[# 교차검증 1 ]\n","\n","학습 레이블 데이터 분포 :\n"," 2    36\n","0    32\n","1    32\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 0    18\n","1    18\n","2    14\n","Name: label, dtype: int64\n","--------------------------------------------------\n","[# 교차검증 2 ]\n","\n","학습 레이블 데이터 분포 :\n"," 2    36\n","1    34\n","0    30\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 0    20\n","1    16\n","2    14\n","Name: label, dtype: int64\n","--------------------------------------------------\n","[# 교차검증 3 ]\n","\n","학습 레이블 데이터 분포 :\n"," 0    38\n","1    34\n","2    28\n","Name: label, dtype: int64 \n","\n","검증 레이블 데이터 분포 :\n"," 2    22\n","1    16\n","0    12\n","Name: label, dtype: int64\n","--------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["## [ '분류 모델' vs '회귀 모델' ]\n","분류모델과 회귀모델은 머신러닝에서 다른 종류의 문제를 해결하는 데 사용되는 두 가지 주요 유형의 모델입니다.<br/><br/>\n","\n","#### 분류모델(Classification Model)\n","\n","- 목적: 입력 데이터를 미리 정의된 클래스 또는 범주 중 하나로 분류하는 것입니다. 이는 주어진 데이터를 여러 그룹 또는 범주로 나누는 작업입니다.\n","- 출력: 이진 분류(두 개의 클래스로 분류) 또는 다중 분류(두 개 이상의 클래스로 분류)일 수 있습니다.\n","- 예시: 스팸 메일 필터링, 손글씨 숫자 인식, 감정 분석 등이 있습니다.<br/><br/>\n","\n","#### 회귀모델(Regression Model)\n","\n","- 목적: 입력 데이터와 관련된 연속적인 값을 예측하는 것입니다. 예측하려는 값은 실수 값이며, 출력은 입력과 관련된 숫자로 이루어집니다.\n","- 출력: 연속적인 값을 가지며, 일반적으로 실수입니다.\n","- 예시: 주택 가격 예측, 주식 가격 예측, 기온 예측 등이 있습니다.<br/><br/>\n","\n","\n","#### < 차이점 요약 >\n","\n","출력 형태: 분류는 이산적인 클래스를 출력하고, 회귀는 연속적인 값을 출력합니다.\n","문제 유형: 분류는 범주를 예측하는 문제에 사용되고, 회귀는 수치 값을 예측하는 문제에 사용됩니다.\n","데이터와 문제의 성격에 따라 적절한 모델을 선택하는 것이 중요합니다."],"metadata":{"id":"dtwsF8Qu8MtQ"}},{"cell_type":"markdown","source":["## cross_val_score()\n","- Scikit-Learn의 cross_val_score() 함수는 기본적으로 회귀 모델에 대해서는 K-Fold 교차 검증 방법을, 분류 모델에 대해서는 Stratified K-Fold 교차 검증 방법을 사용합니다.\n","\n","- 분류 모델에서 cross_val_score()를 사용하면, 데이터의 클래스 비율을 유지하며 데이터를 나누는 Stratified K-Fold 방식이 기본적으로 적용됩니다.\n","\n","- 다만, 이는 기본 설정이며, 필요에 따라 cv 파라미터를 사용하여 다른 교차 검증 방법을 지정할 수 있습니다. 예를 들어, cv=KFold(n_splits=5) 와 같이 지정하면 5-Fold 교차 검증을 사용하게 됩니다."],"metadata":{"id":"r2cqnogR77Ck"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_val_score, cross_validate\n","from sklearn.datasets import load_iris\n","\n","iris_data = load_iris()\n","dt_clf = DecisionTreeClassifier(random_state=156)\n","\n","data = iris_data.data\n","label = iris_data.target\n","\n","# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n","scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n","\n","print('교차 검증별 정확도:', np.round(scores, 4))\n","print('평균 검증 정확도:', np.round(np.mean(scores), 4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHuJ8rYe8vfP","executionInfo":{"status":"ok","timestamp":1706158274247,"user_tz":-540,"elapsed":346,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"e42791fc-1306-48af-ea84-19045051f226"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["교차 검증별 정확도: [0.98 0.94 0.98]\n","평균 검증 정확도: 0.9667\n"]}]},{"cell_type":"markdown","source":["## GridSearchCV\n","- GridSearchCV는 scikit-learn 라이브러리에서 제공하는 클래스로, 지정된 하이퍼파라미터의 모든 가능한 조합에 대해 교차 검증을 수행하여 최적의 하이퍼파라미터를 찾는 방법.\n","\n","- 하이퍼파라미터는 머신러닝 모델의 성능을 조절(규제)하는 매개변수들이다. 예를 들어, 서포트 벡터 머신(SVM)에서는 마진의 넓이를 조절하는 C나 커널의 종류를 결정하는 kernel 등이 하이퍼파라미터가 된다. 이러한 하이퍼파라미터는 학습 데이터로부터 학습되는 것이 아니라, 사람이 직접 설정해주어야 한다.\n","\n","- GridSearchCV는 이러한 하이퍼파라미터를 효과적으로 설정하기 위한 도구입니다. 사용자가 지정한 범위 내에서 모든 하이퍼파라미터 조합을 시도하고, 각 조합에 대해 교차 검증을 수행하여 가장 성능이 좋은 조합을 찾는다.\n","\n","- GridSearchCV의 주요 파라미터는 다음과 같다:\n","    - estimator: 사용할 머신러닝 모델.\n","    - param_grid: 하이퍼파라미터의 종류와 시도해 볼 값들을 사전 형태로 지정.\n","    - scoring: 모델의 성능을 평가하는 지표를 지정.\n","    - cv: 교차 검증을 수행할 때 데이터를 나누는 폴드의 개수를 지정.\n","- GridSearchCV를 사용하면, 각각의 하이퍼파라미터 조합에 대해 성능을 자동으로 평가하므로, 수작업으로 각각의 조합을 시도해 볼 필요가 없다. 이는 시간을 절약하고, 또한 객체 지향 프로그래밍 방식을 사용하여 코드를 더욱 간결하고 이해하기 쉽게 만든다.\n","- 하지만 GridSearchCV는 모든 조합을 시도하므로, 하이퍼파라미터의 개수나 시도해 볼 값의 개수가 많아지면 계산 비용이 크게 증가할 수 있다."],"metadata":{"id":"TH9Z0I3t98Bf"}},{"cell_type":"markdown","source":["#### [참고] Decision Tree에서의 주요 하이퍼파라미터\n",": max_depth(최대 깊이), &#160; min_samples_split(최소 샘플 분할), &#160; min_samples_leaf(최소 샘플 리프), &#160; max_features(최대 기능), &#160; criterion(기준, gini/entropy), &#160; max_leaf_nodes(최대 리프노드)"],"metadata":{"id":"rn24s2HQCc-k"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","\n","# 데이터를 로딩하고 학습데이터와 테스트 데이터 분리\n","iris_data = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n","dtree = DecisionTreeClassifier()\n","\n","# parameter들을 dictionary 형태로 설정\n","parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n","\n","# param_grid의 하이퍼 파라미터들을 3개의 train, test-set fold로 나누어서 테스트 수행 설정\n","grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)     # refit=True가 default (True이면 가장 좋은 파라미터 설정으로 재 학습시킴)\n","\n","# 붓꽃 Train 데이터로 param_grid의 하이퍼파라미터들을 순차적으로 학습/평가\n","grid_dtree.fit(X_train, y_train)\n","\n","print(grid_dtree)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaeVpPsnCcVn","executionInfo":{"status":"ok","timestamp":1706160614387,"user_tz":-540,"elapsed":348,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"9adbf54e-1b84-443f-e754-6b33f873652e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n","             param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]})\n"]}]},{"cell_type":"code","source":["print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n","print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1etd33NDLMQ","executionInfo":{"status":"ok","timestamp":1706195399549,"user_tz":-540,"elapsed":336,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"24b49a37-8f9b-4c20-a42b-2f78fa77aab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n","GridSearchCV 최고 정확도: 0.9750\n"]}]},{"cell_type":"code","source":["# GridSearchCV의 refit으로 이미 학습이 된 extimator 반환\n","estimator = grid_dtree.best_estimator_\n","\n","# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨.\n","pred = estimator.predict(X_test)\n","print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQ9YvdcSHOh7","executionInfo":{"status":"ok","timestamp":1706161229191,"user_tz":-540,"elapsed":309,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"624ab6a0-bafb-4460-e31f-b1ec63178105"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 데이터 세트 정확도: 0.9667\n"]}]},{"cell_type":"markdown","source":["Q. 와인 데이터에 대해서 아래 사항을 고려하여 모델 생성 및 성능 개선을 위한 하이퍼파라미터 튜닝을 수행하세요.\n","\n","- dt를 알고리즘으로 적용\n","- cv = 5\n","- param_grid = {'max_depth':[3,4,5,6], 'min_samples_split':[2,3,4]}"],"metadata":{"id":"a-FtBw-IJMmq"}},{"cell_type":"code","source":["# GridSearchCV를 사용한단 소리는 cross_val_score()를 사용한다는 소리임. (∴ cv갯수를 설정)\n","# 데이터의 클래스 비율을 유지하며 데이터를 나누는 Stratified K-Fold 방식이 기본적으로 적용\n","\n","from sklearn import datasets\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# 와인 데이터 불러오기\n","wine = datasets.load_wine()\n","X, y = wine.data, wine.target\n","print(\"Wine 데이터의 key값 확인: \", wine.keys(), '\\n')\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=121, stratify=y)        # 교차검증에 들어가기 전에 학습용(train) 데이터와 평가용(test) 데이터를 구분\n","dtree = DecisionTreeClassifier(random_state=1)          # random_state를 주지 않으면 코드를 실행할때마다 객체가 변경되기 때문에 시행 결과도 바뀜.\n","\n","# parameter들을 dictionary 형태로 설정\n","# parameters = {'max_depth':[5, 6, 7, 8], 'min_samples_split':[2, 3, 4]}        # GridSearchCV 최적 파라미터: {'max_depth': 5, 'min_samples_split': 2}\n","parameters = {'max_depth':[3, 4, 5, 6], 'min_samples_split':[2, 3, 4]}          # GridSearchCV 최적 파라미터: {'max_depth': 4, 'min_samples_split': 2}\n","      # >>> parameters에서 max_depth의 값을 변경해서 확인해서 최적의 max_depth는 4.\n","\n","# param_grid의 하이퍼 파라미터들을 5개의 train, test-set fold로 나누어서 테스트 수행 설정 (5개로 나누는 것의 원본 데이터는 교차 검증에 들어오기 전 학습용(train) 데이터를 가지고 나눔.)\n","grid_search = GridSearchCV(dtree, param_grid=parameters, cv=5, refit=True)     # refit=True가 default (True이면 가장 좋은 파라미터 설정으로 재 학습시킴)\n","\n","# wine Train 데이터로 param_grid의 하이퍼파라미터들을 순차적으로 학습 및 교차 검증(평가)\n","grid_search.fit(X_train, y_train)\n","\n","print(\"[ 학습 내용 ] \\n\", grid_search, '\\n')\n","\n","print('GridSearchCV 최적 파라미터:', grid_search.best_params_)\n","print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_search.best_score_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"FxMwKnW2Jcvd","executionInfo":{"status":"error","timestamp":1706234488878,"user_tz":-540,"elapsed":1711,"user":{"displayName":"한정현","userId":"04742589720279403748"}},"outputId":"22fea573-bd6b-42fe-9a77-b46a8466e1a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wine 데이터의 key값 확인:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names']) \n","\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'train_test_split' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a1cffdd3707a>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wine 데이터의 key값 확인: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# 교차검증에 들어가기 전에 학습용(train) 데이터와 평가용(test) 데이터를 구분\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# random_state를 주지 않으면 코드를 실행할때마다 객체가 변경되기 때문에 시행 결과도 바뀜.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"]}]},{"cell_type":"code","source":["# 교차 검증에 들어오기 전 학습용(train) 데이터를 가지고 나눔.\n","\n","# GridSearchCV의 refit으로 이미 학습이 된 extimator 반환\n","estimator = grid_search.best_estimator_\n","\n","# GridSearchCV의 beest_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨.\n","pred = estimator.predict(X_test)\n","print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKaXRxFUTg82","executionInfo":{"status":"ok","timestamp":1706164829594,"user_tz":-540,"elapsed":393,"user":{"displayName":"김신미","userId":"03496124473786773744"}},"outputId":"8e557523-3f83-41f2-8520-772ee83423f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 데이터 세트 정확도: 0.8889\n"]}]},{"cell_type":"markdown","source":["Q. 타이타닉 생존자 예측 데이터 세트 train.csv에 대하여 다음 사항을 수행하세요.\n","- 일괄 전처리 사용자 함수 transform_features(df) 작성\n","- dt, lr, rf 모델링 및 평가(정확도)\n","- dt_clf , folds=5 적용하여 KFold 교차검증 수행\n","- dt_clf , cv=5 적용, cross_val_score를 이용하여 교차검증 수행\n","- GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행.\n","  - parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n","  - dt_clf, scoring='accuracy', cv=5 적용"],"metadata":{"id":"xivAsDUmlE9o"}}]}